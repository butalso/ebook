# MQ-kafka

## 什么是kafka
Kafka起初是由Linkedin公司采用Scala语言开发的一个多分区、多副本且基于ZooKeeper协调的分布式消息系统，现己被捐献给Apache基金会。目前Kafka已经定位为一个分布式流式处理平台，它以高吞吐、可持久化、可水平扩展、支持流数据处理等多种特性而被广泛使用。

## kafka的用途有那些，使用场景如何
### 用途
* 消息系统：kafka与其他消息中间件都具备系统解耦、流量削峰、异步处理、弹性伸缩等功能。同时，kafka还提供其他大多数消息中间件难以实现的消息顺序性保障和回溯消费的功能。
* 存储系统：kafka可将消息持久化到磁盘，且可以多副本存储，通过设置数据保留策略为”永久”来作为长期数据存储系统来使用。
* 流式处理平台：Kafka提供了一个完整流式处理类库，比如窗口，连接，变换和聚合等操作。
### 消息系统使用场景
* 异步处理：非核心流程异步化，减少系统响应时间，提高吞吐量。例如：短信通知、终端状态推送、App推送、用户注册等。
* 系统解耦：系统之间不是强耦合的，消息接受者可以随意增加，而不需要修改消息发送者的代码。消息发送者的成功不依赖消息接受者（比如：有些银行接口不稳定，但调用方并不需要依赖这些接口）。
* 最终一致性：最终一致性不是消息队列的必备特性，但确实可以依靠消息队列来做最终一致性的事情。先写消息再操作，确保操作完成后再修改消息状态。定时任务补偿机制实现消息可靠发送接收、业务操作的可靠执行，要注意消息重复与幂等设计。所有不保证 100% 不丢消息 的消息队列，理论上无法实现 最终一致性。
* 流量削峰：当上下游系统处理能力存在差距的时候，利用消息队列做一个通用的“漏斗”，进行限流控制。在下游有能力处理的时候，再进行分发。
* 日志处理：将消息队列用在日志处理中，比如Kafka的应用，解决海量日志传输和缓冲的问题。

## Kafka中的ISR、AR又代表什么？ISR的伸缩又指什么
`AR=ISR+OSR`
* ISR: in-sync replicas，和leader副本保持在可接受滞后范围的副本列表
* OSR：out-of-sync replicas，与leader副本同步滞后过多的副本列表
* AR: asigned replicas，所有副本列表
### ISR伸缩
ISR伸缩指的是ISR集合副本数量的扩张和收缩。kafka在启动时会开启两个和ISR相关的任务，`isr-expiration`和`isr-change-propagation`，`isr-expiration`任务周期性的检测每个分区是否需要缩减其ISR集合，当检测到ISR集合中有失效副本时，就会收缩ISR集合。同样，随着follower副本不断与leader副本进行消息同步，follower副本的LEO会逐渐后移，并最终赶上leader副本（LEO不小于leader副本的HW），此时，follower副本可以加入ISR集合。当ISR集合发生增减、或者ISR集合的任一副本的LEO发生变化时，都会影响整个分区的HW。`isr-change-propagation`任务周期性检查`isrChangeSet`，当发现有ISR集合变更记录，就会在Zookeeper的`/isr_change_notification`路径下创建以`_isr_change_`开头的持久顺序节点，Kafka控制器监听该节点并向它管理的broker节点发送变更元数据的请求。
#### 失效副本
失效副本判定两个参数：
* replica.lag.max.messages：当follower副本滞后leader副本消息数超过该参数时，则判定为失效
* replica.lag.time.max.ms：当follower副本上一次将leader副本LEO之前的日志全部同步时的lastCaughtUpTimeMs值大于该参数时，则判定为失效

一般产生原因有：
* follower副本进程卡住，在一段时间内根本没有向leader副本发起同步请求，比如频繁的FullGC
* follower副本进程同步过慢，在一段时间内都无法追赶上leader副本，比如IO开销过大

## Kafka中的HW、LEO、LSO、LW等分别代表什么？
* HW：High Watermark，俗称高水位，它标识一个特定的消息偏移量（offset），消费者只能拉取到这个offset之前的消息。
* LEO：Log End Offset，它标识当前日志文件中下一条代写入消息的offset，相当于当前日志分区中最后一条消息的offset+1，分区ISR集合中每个副本都会维护自身的LEO，而ISR集合中最小的LEO及为分区的HW，而消费者也只能消费HW之前的消息。
* LSO：Last Stable Offset，对未完成的事务而言，LSO的值等于事务中第一条消息的位置(firstUnstableOffset)，对已完成的事务而言，它的值同HW相同。`LSO<=HW<=LEO`
* LW：Low Watermark，低水位，代表AR集合中最小的LogStartOffset值

## Kafka中是怎么体现消息顺序性的？
Kafka的消息有序通过offset体现的，offset是消息在分区中的唯一标识，Kafka通过offset保证消息在分区内的有序性，但是offset不能跨越分区，所以Kafka的消息有序性只体现在分区有序而不是主题有序。

值得一提的是，当acks参数为非0值，且max.in.flight.requests.per.connection参数为配置大于1的值时，那就有可能出现错序现象，比如第一批消息写入失败，第二批消息写入成功，生产者重试发送第一批消息写入成功，那么这两个批次的消息发送时就出现了错序。

## Kafka中分区器、序列化器、拦截器是否了解？它们之间的处理顺序是什么？
* 生产者顺序：拦截器->序列化器->分区器
* 消费者：反序列化器->拦截器
### 拦截器
#### 生产者拦截器
拦截器可以用来在消息发送前做一些准备工作，比如按照某个规则过滤不符合要求的消息、修改消息的内容等，也可以用来在发送回调逻辑前做一些定制化的需求，比如统计类工作。包含三个方法`onSend,onAcknowledgement,close`
* onSend：在消息序列化和计算分区之前调用
* onAcknowledgement：消息被应答之前或消息发送失败时调用
* close：关闭拦截器时执行一些资源的清理工作
#### 消费者拦截器
消费者拦截器也有三个方法`onConsume,onCommit,close`
* onConsume：在poll()方法返回之前调用，可以进行相应的定制化操作，比如修改返回的消息内容、按照某种规则过滤消息
* onCommit：提交完消费位移之后调用，可以用来记录跟踪所提交的位移信息
* close：关闭拦截器时执行一些资源的清理工作
### 序列化器&反序列化器
生产者需要用序列化器把对象转换成字节数组才能通过网络发送给Kafka，而在对侧，消费者需要用反序列化器把从Kafka中收到的字节数组转换成相应的对象。生产者使用的序列化器和消费者使用的反序列化器是需要一一对应的。序列化器包含三个方法`configure,serialize,close`，反序列化器包含三个方法`configure,deserialize,close`
### 分区器
消息经过序列化之后就需要确定它发往的分区，如果消息ProducerRecord中指定了partition字段，那么就不需要分区器的作用，因为partition代表的就是所要发往的分区号。如果消息ProducerRecord中没有指定partition字段，那么就需要依赖分区器。如果key值不为null，分区器会对key进行hash，根据最终得到的hash值来计算分区号；如果key为null，那么Producer将会把这条消息发送给随机的一个Partition。分区器包含三个方法`configure,partition,close`

## Kafka生产者客户端的整体结构是什么样子的？
整个生产者客户端由主线程、发送线程两个线程协调运行。KafkaProducer在主线程中创建消息，然后通过拦截器、序列化器、分区器作用之后缓存到消息累积器（RecordAccumulator），发送线程负责从消息累积器中获取消息并将其发送到Kafka中。
### 消息累积器（RecordAccumulator）
消息累积器主要用来缓存消息以便发送线程可以批量发送，进而减少网络传输的资源消耗以提升性能。缓存大小由客户端参数`buffer.memory`控制，默认为32MB。如果生产者发送消息的速度超过发送到服务器的速度，则会导致生产者空间不足，这时，KafkaProducer调用send()方法要么被阻塞，要么抛出异常。

消息累积器为每个分区维护一个双端队列，队列内容是ProducerBatch，消息写入缓存时，追加到双端队列尾部。发送线程从队列头部读取ProducerBatch。ProducerBatch表示一个消息批次，可以包含一个到多个ProducerRecord，这样可以使字节的使用更加紧凑，同时，将较小的ProducerRecord拼凑成一个较大的ProducerBatch，这样可以减少网络请求次数以提升整体吞吐量。

在消息累积器内部还使用了BufferPool来实现ByteBuffer的复用，避免频繁的内存申请和释放。由参数`batch.size`指定大小。

发送线程从消息累积器中获取缓存的消息后，会进一步将原本`<Partition, Deque<ProducerBatch>>`的保存形式转变成`<Node, List<ProducerBatch>>`的形式。因为对于网络连接来说，生产者客户端是与具体的broker节点建立连接，并不关心消息属于哪一个分区；而对于KafkaProducer的应用逻辑而言，只关注向哪个分区发送消息，所以，这里做了一个应用逻辑层面到网络IO层面的转换。

## Kafka的旧版Scala的消费者客户端的设计有什么缺陷？
旧版消费者基于Zookeeper的Watcher来实现功能，每个消费者对相关的路径进行监听，当触发再均衡操作时，一个消费者组下的所有消费者会同时进行在均衡操作，而消费者之间并不知道彼此操作的结果，可能会导致Kafka工作在一个不正确的状态。与此同时，过度依赖Zookeeper集群还有羊群效应、脑裂两个问题：
* 羊群效应：Zookeeper中一个被监听的节点变化，大量的Watcher事件通知被发送到客户端，导致在通知期间的其他操作延迟，也可能发生死锁问题。
* 脑裂问题：消费者再均衡操作时，每个消费者都与Zookeeper进行通信以判断消费者或Broker变化的情况，由于Zookeeper本身的特性，可能导致同一时刻的消费者获取的状态不一致。

## “消费组中的消费者个数如果超过topic的分区，那么就会有消费者消费不到数据”这句话是否正确？如果不正确，那么有没有什么hack的手段？
不正确。自定义分区分配策略使一个分区可以分配给多个消费者消费

## 消费者提交消费位移时提交的是当前消费到的最新消息的offset还是offset+1?
当前消费者需要提交的offset并不是offset，而是offset+1，它标识下一条需要拉取消息的位置

## 有哪些情形会造成重复消费？
一次拉取多条消息，消息全部处理完成再进行位移提交。若消费者在处理了部分消息之后异常宕机，则此时没有进行位移提交，故障恢复后消费者再次拉取的消息还是从宕机前最后一次提交的offset开始。则会产生重复消费消息。

## 那些情景下会造成消息漏消费？
一次拉取多条消息，拉取消息之后马上进行了位移提交。消费者在处理了部分消息之后异常宕机，故障恢复之后拉取到的是已经位移提交之后的值，未处理的消息则被漏消费（漏处理）。

## KafkaConsumer是非线程安全的，那么怎么样实现多线程消费？
KafkaConsumer定义了一个acquire方法，用来检查当前是否只有一个线程在操作，若有其他线程正在操作此KafkaConsumer，则会抛出ConcurrentModifcationException异常
* 每一个消费线程单独持有一个KafkaConsumer对象，但是此方法线程数受限于分区的实际个数。
* 单线程接收消息，多线程处理消息，但此方法会导致消息无法顺序处理，手动位移提交需要特别设计。

## 简述消费者与消费组之间的关系
* 若所有的消费者都属于同一个消费组，那么所有的消息都会被均衡的投递给每一个消费者，即每条消息只会被一个消费者处理，这就相当于“点对点”模式的应用
* 若所有的消费者都隶属于不同的消费组，那么所有的消息都会被广播给所有的消费者，即每条消息都会被所有的消费者处理，这就相当于“发布/订阅”模式的应用

## 当你使用kafka-topics.sh创建（删除）了一个topic之后，Kafka背后会执行什么逻辑？
### 创建topic
1. 在zookeeper的路径`/brokers/topics/{topic-name}`创建与待创建主题同名的节点。
2. kafka控制器监听到该节点变化，读取并检查新建主题的配置信息，比如主题名称是否合法，然后执行分区副本分配，在对应broker下log.dir或者log.dirs参数所配置的目录下创建相应的主题分区
### 删除topic
1. 在ZooKeeper的路径`/admin/delete_topics`创建与待删除主题同名的节点。
2. kafka控制器监听到该节点变化，判断该主题是否存在且可以删除，删除与zookeeper中该主题相关的节点和broker中对应的日志文件。

## topic的分区数可不可以增加？如果可以怎么增加？如果不可以，那又是为什么？
可以增加。通过`topic-topic.sh`脚本中的alter命令执行分区增加操作。值得注意的是，当分区数变化时，生产者中的分区器根据key计算分区的行为就会受到影响。

## topic的分区数可不可以减少？如果可以怎么减少？如果不可以，那又是为什么？
不可以减少。实现该功能需要考虑很多因素，比如待删除的分区中消息如何处理，消息的顺序性、事务性，分区和副本的状态机如何转换。这会使得代码复杂度急剧增加。而且，通过重新创建一个分区数较小的主题，将现有主题中的消息按照既定逻辑复制过去也可以实现此功能。

## 创建topic时如何选择合适的分区数？
分区数的选择视具体情况而定。增加合适的分区数可以在一定程度上提升整体的吞吐量，但超过对应的阈值之后吞吐量不升反降，建议在生产环境中做一个完备的测试找到合适分区数与阈值。一般情况下，根据预估的吞吐量及是否与key相关的规则来设定分区数即可，后期可以通过增加分区数、增加broker或分区重分配等手段来进行改进。如果一定要给一个准则，则建议将分区数设定为集群中broker的倍数，即假定集群中有3个broker节点，可以设定分区数为3、6、9等，至于倍数的选定可以参考预估的吞吐量。不过，如果集群中的broker节点数有很多，比如大几十或上百、上干，那么这种准则也不太适用，在选定分区数时进一步可以引入基架等参考因素。
### 分区数过多带来的问题
* 占用过多的系统资源，比如文件描述符，影响kafka正常启动与关闭耗时
* 影响系统可用性。当多个分区的leader副本被分配到同一个broker节点且该broker节点宕机时，就会有大量的分区需要同时进行leader角色切换，这个过程将会耗费一定的时间，而在这个时间窗口这些分区将处于不可用状态。

## Kafka目前有那些内部topic，它们都有什么特征？各自的作用又是什么？
* __consumer_offsets：用于存放存放消费者偏移量
* __transcation_state：用于持久化事务状态信息。

## 优先副本是什么？它有什么特殊的作用？
优先副本是指在AR集合列表中第一个副本。理想情况下，优先副本就是该分区的leader副本，Kafka会确保所有的主题的优先副本在集群中均匀分布。
### 优先副本的选举
优先副本的选举是指通过一定的方式促使优先副本选举为leader副本，以此来促进集群的负载均衡，这一行为也可以称为“分区平衡”。kafka提供分区自动平衡的功能，参数`auto.leader.rebalance.enable`，默认为true，即开启状态。当开启自动平衡功能时，kafka控制器将启动一个定时任务，轮询所有broker节点并计算broker节点的分区不平衡率是否超过`leader.imbalance.per.broker.percentage`参数的配置，如果超过则会自动执行优先副本的选举动作以求分区平衡。
### 是否应该开启自动平衡功能
* 分区平衡不代表负载均衡，生产环境不建议将`auto.leader.rebalance.enable`置为true，避免关键时候执行优先副本选举造成业务超时阻塞，因为leader副本转移是一件高成本的事情
* 在实际生产环境中，一般使用`path-to-json-file`参数来分批、手动地执行优先副本的选举操作。尤其是在应对大规模的Kafka集群时，理应杜绝采用非`path-to-json-file`参数的选举操作方式。同时，优先副本的选举操作也要注意避开业务高峰期，以免带来性能方面的负面影响 。

## Kafka有哪几处地方有分区分配的概念？简述大致的过程及原理、
### 生产者
生产者的分区分配是指为每条消息指定其所要发往的分区
### 消费者
为消费者指定其可以消费消息的分区
### kafka集群
#### 主题创建
在哪个broker中创建哪些分区的副本，一个分区的所有副本必须分配到不同的broker节点上。有两种方式
##### 手动指定分区分配方案
##### `assignReplicasToBrokersRackUnaware`计算
一个随机的起始索引`startIndex`，相对于前一次分配的偏移量`nextReplicaShift`。同时满足以下任意一个条件的`broker`不能被添加到当前分区的副本列表之中：
* 如果此broker所在的机架中己经存在一个broker拥有该分区的副本，并且还有其他的机架中没有任何一个broker拥有该分区的副本。
* 如果此broker中己经拥有该分区的副本，并且还有其他broker中没有该分区的副本。
#### 分区重分配
集群负载不均衡的原因
* 节点宕机下线，如果该节点上的分区是多副本的，则位于该节点上的leader副本的角色会迁移到其他节点的follower副本上，即使该节点重新上线，也是以follower副本身份恢复
* 要对集群中的某一节点进行有计划的下线，为了保证分区及副本分配合理，期望通过某种方式能够将该节点的分区副本迁移到其他可用节点上
* 集群中新增broker节点，只有新创建的主题分区才有可能被分配到这个节点上

为了解决上述问题，需要让分区副本再次进行合理的分配，也就是分区重分配。kafka提供`kafka-reassign-partitions.sh`脚本执行分区重分配工作，可以在集群扩容，broker节点失效的场景下对分区进行迁移。`kafka-reassign-partitions.sh`脚本的使用分为3个步骤: 首先创建一个包含主题清单的JSON文件，其次根据主题清单和broker节点清单生成一份重分配方案，最后根据这份方案执行具体的重分配动作。

## 简述Kafka的日志目录结构
不考虑多副本的情况，一个分区对应一个日志(Log)。为了防止Log过大，Kafka又引入了日志分段(LogSegment)的概念，将Log切分为多个LogSegment，相当于一个巨型文件被平均分配为多个相对较小的文件，这样也便于消息的维护和清理。但是Log和LogSegnient并不是纯粹物理意义上的概念，Log在物理上只以文件夹的形式存储，以`<topic>-<partition>`的方式命名，而每个LogSegment对应于磁盘上的一个日志文件（`.log`）和两个索引文件（偏移量索引文件`.index`、时间戳索引文件`.timeindex`），文件名前缀为固定20位数字（没达到20位数字则用0填充）基准偏移量。只有最后一个LogSegament才能执行写入操作，即活跃的日志分段。随着消息的不断写入，当活跃的日志分段满足一定条件时，就需要创建新的活跃日志分段，之后追加的消息将写入新的活跃日志分段。
### 日志分段文件切分
日志文件需要切分时，其对应的索引文件也会被切分，满足以下任一条件即可。
* 当前日志分段文件的大小超过了broker端参数`log.segment.bytes`配置的值，默认为1GB
* 当前日志分段中消息的最大时间戳与当前系统的时间戳的差值大于`log.roll.ms`或`log.roll.hours`参数配置的值。如果同时配置了`log.roll.ms`和`log.roll.hours`参数，那么`log.roll.ms`的优先级高。
* 偏移量索引文件或时间戳索引文件的大小达到broker端参数`log.index.size.max.bytes`配置的值,默认为1OMB。
* 追加的消息的偏移量与当前日志分段的偏移量之间的差值大于`Integer.MAX_VALUE`，即要追加的消息的偏移量不能转变为相对偏移量(`offset - baseOffset > Integer.MAX_VALUE`)

## Kafka中有那些索引文件？
kafka每个日志分段对应两个索引文件，偏移量索引文件`.index`和时间戳索引文件`.timeindex`，偏移量索引文件用来建立消息偏移量(offset)到物理地址之间的映射关系，方便快速定位消息所在的物理文件位置;时间戳索引文件则根据指定的时间戳(timestamp)来查找对应的偏移量信息。

Kafka中的索引文件以稀疏索引(sparse index)的方式构造消息的索引，并不保证每个消息在索引文件中都有对应的索引项。每当写入一定量(由broker端参数`log.index.interval.bytes`指定，默认值为4096，即4KB)的消息时，偏移量索引文件和时间戳索引文件分别增加一个偏移量索引项和时间戳索引项，增大或减小`log.index.interval.bytes`的值，对应地可以增加或缩小索引项的密度。通过MappedByteBuffer可以将索引文件映射到内存中，加快索引的查询速度。

## 如果我指定了一个offset，Kafka怎么查找到对应的消息？
偏移量索引文件的每个索引项包含两部分，相对偏移量（relativeOffset，4字节）、物理地址（position，4字节）
1. 因为偏移量索引文件中的偏移量是单调递增的，在查询指定偏移量时，使用二分查找法来快速定位偏移量的位置，如果指定的偏移量不在索引文件中，则会返回小于指定偏移量的最大偏移量
2. 计算消息offset在偏移量索引文件中的相对偏移量，找到对应的索引项，找到对应的物理地址
3. 在日志分段文件中找到对应物理位置的消息

## 如果我指定了一个timestamp，Kafka怎么查找到对应的消息？
时间戳索引文件的每个索引项包含两部分，时间戳（timestamp，8字节）、相对偏移量（relativeOffset，4字节）
1. 时间戳索引文件中的时间戳也保持严格的单调递增，查询指定时间戳时，也根据二分查找法来查找不大于该时间戳的索引文件
2. 在时间戳索引文件中，找到时间戳不大于该指定时间戳的所影响，得到对应的相对偏移量。
3. 根据相对偏移量在偏移量索引文件中找到对应的索引项，找到对应的物理地址
4. 在日志分段文件中找到对应物理位置的消息

## 日志清理
kafka提供两种日志清理策略，即日志删除（Log Retention）、日志压缩（Log Compaction）。
### 聊一聊你对Kafka的Log Retention的理解
Log Retention即按照一定的保留策略直接删除不符合条件的日志分段。主要分为下面三种策略：
* 基于时间：日志删除任务会检查当前日志文件中是否有保留时间超过设定阈值的日志分段文件集合。阈值可以通过broker端参数`log.retention.hours`、`log.retention.minutes`和`log.retention.ms`来配置，优先级依次提高，默认为七天。
* 基于日志大小：日志删除任务会检查当前日志文件的总文件大小超过设定阈值。计算出需要删除的日志总大小，然后从日志文件的第一个日志分段查找可删除的日志分段集合，执行删除操作
* 基于日志起始偏移量：基于日志起始偏移量的保留策略的判断依据是某日志分段的下一个日志分段的起始偏移量baseOffset是否小于logStartOffset，若是则可以删除此日志分段。
### 聊一聊你对Kafka的Log Compaction的理解
日志压缩即有相同key，但是value不同的消息，只保留最后一个版本。日志压缩需要做两次遍历操作，第一次把每个key的哈希值和最后出现的offset保存到SkimpyOffsetMap中，第二次遍历会检查每个消息是否符合保留条件，符合则保留下来。同时为了防止日志压缩后出现过多小文件，kafka在实际清理过程中并不对单个日志分段进行单独清理，而是将日志分段分组，同一个组的日志分段清理完成后，只会生成一个新的日志分段

## 聊一聊你对Kafka底层存储的理解（页缓存、内核层、块层、设备层）
### 磁盘顺序读写
一般来说，操作系统存储分为多级结构，从磁带、磁盘、主存、高速缓存到寄存器缓存，层级越高代表速度越快，价格也越昂贵。kafka依赖于磁盘存储来存储消息，采用文件追加的方式写入消息，即只能在日志文件尾部追加新的消息，并且也不允许修改已写入的消息，即kafka只按照顺序读写磁盘。操作系统针对顺序读写方式做了优化，包括预读（read-ahead）、后写（write-behind）技术。测试结果表示，顺序写盘速度不仅比随机写盘速度快，也比随机写内存的速度快。
### 操作系统页缓存
kafka采用了大量的页缓存技术，这也是kafka实现高吞吐的重要因素之一。页缓存是操作系统实现磁盘缓存中重要的一种方式，以此用来减少对磁盘I/O的操作。具体来说，就是把磁盘中的数据缓存到内存中，把对磁盘的访问改变为对内存的访问。当一个进程准备读取磁盘上的文件内容时，操作系统会先查看待读取的数据所在的页(page)是否在页缓存(pagecache)中，如果存在(命中〉则直接返回数据，从而避免了对物理磁盘的I/O操作;如果没有命中，则操作系统会向磁盘发起读取请求并将读取的数据页存入页缓存，之后再将数据返回给进程。同样，如果一个进程需要将数据写入磁盘，那么操作系统也会检测数据对应的页是否在页缓存中，如果不存在，则会先在页缓存中添加相应的页，最后数据写入对应的页。被修改过后的页也就变成了脏页，操作系统会在合适的时间把脏页中的数据写入磁盘，以保持数据的一致性。
### 操作系统零拷贝
除了消息顺序追加、页缓存等技术，Kafka还使用零拷贝（Zero-Copy）技术来进一步提升性能。所谓的零拷贝是指将数据直接从磁盘文件复制到网卡设备中，而不需要经由应用程序之手。零拷贝大大提高了应用程序的性能，减少了内核和用户模式之间的上下文切换。在Linux操作系统中，零拷贝技术依赖于底层的sendfile()方法实现。

## 聊一聊Kafka的延时操作的原理
延时操作即由于当前时间点得不到响应结果，需要延时等待，在一个超时时间范围内，能够由外部事件触发完成；如果超时时间过后没有完成既定的任务，则强制返回一个响应结果给客户端 。Kafka中有多种延时操作，比如延时生产，还有延时拉取。延时操作在创建之后会被加入延时操作管理器来做专门的处理。因为延时操作有可能会超时，所以管理器会给每个延时配置一个定时器（SystemTimer）来做超时管理，定时器的底层就是采用时间轮（TimingWheel）实现。同时，延时操作需要支持外部事件的触发，所以还有一个监听池来负责监听每个分区的外部事件。收割机线程`ExpiredOperationReaper`不仅会推进时间轮，还会定期清理监听池中已完成的延时操作。
### 延时生产
当设置`acks=-1`，则意味着生产者需要等待ISR集合中所有的副本都确认收到消息之后才能正确的收到响应的结果，或者捕获超时异常。kafka将消息写入leader副本的本地日志文件后，将创建一个延时的生产操作。延时生产操作的外部事件是某个分区的HW发生增长。
### 延时拉取
在一次拉取请求中，会先读取一次日志文件，如果收集不到足够多的消息，则会创建一个延时拉取操作以等待足够数量的消息。如果是follower副本的拉取，外部事件即为有新消息追加到leader副本的日志文件中；如果是消费者客户端的拉取，外部事件即为分区HW的增长。

## 聊一聊Kafka控制器的作用

消费再均衡的原理是什么？（提示：消费者协调器和消费组协调器）

Kafka中的幂等是怎么实现的

Kafka中的事务是怎么实现的（这题我去面试6家被问4次，照着答案念也要念十几分钟，面试官简直凑不要脸。实在记不住的话...只要简历上不写精通Kafka一般不会问到，我简历上写的是“熟悉Kafka，了解RabbitMQ....”）

Kafka中有那些地方需要选举？这些地方的选举策略又有哪些？

失效副本是指什么？有那些应对措施？

多副本下，各个副本中的HW和LEO的演变过程

为什么Kafka不支持读写分离？

Kafka在可靠性方面做了哪些改进？（HW, LeaderEpoch）

Kafka中怎么实现死信队列和重试队列？

Kafka中的延迟队列怎么实现（这题被问的比事务那题还要多！！！听说你会Kafka，那你说说延迟队列怎么实现？）

Kafka中怎么做消息审计？

Kafka中怎么做消息轨迹？

Kafka中有那些配置参数比较有意思？聊一聊你的看法

Kafka中有那些命名比较有意思？聊一聊你的看法

Kafka有哪些指标需要着重关注？

怎么计算Lag？(注意read_uncommitted和read_committed状态下的不同)

Kafka的那些设计让它有如此高的性能？

Kafka有什么优缺点？

还用过什么同质类的其它产品，与Kafka相比有什么优缺点？

为什么选择Kafka?

在使用Kafka的过程中遇到过什么困难？怎么解决的？

怎么样才能确保Kafka极大程度上的可靠性？

聊一聊你对Kafka生态的理解

## 参考链接
* <https://mp.weixin.qq.com/s/I-YsRKcjcBv4eOop-jjO0A>
* <https://juejin.im/post/5b41fe36e51d45191252e79e>
* <https://www.dazhuanlan.com/2019/10/27/5db52fbab04aa/>