# MQ-kafka

## 什么是kafka
Kafka起初是由Linkedin公司采用Scala语言开发的一个多分区、多副本且基于ZooKeeper协调的分布式消息系统，现己被捐献给Apache基金会。目前Kafka已经定位为一个分布式流式处理平台，它以高吞吐、可持久化、可水平扩展、支持流数据处理等多种特性而被广泛使用。

## kafka的用途有那些，使用场景如何
### 用途
* 消息系统：kafka与其他消息中间件都具备系统解耦、流量削峰、异步处理、弹性伸缩等功能。同时，kafka还提供其他大多数消息中间件难以实现的消息顺序性保障和回溯消费的功能。
* 存储系统：kafka可将消息持久化到磁盘，且可以多副本存储，通过设置数据保留策略为”永久”来作为长期数据存储系统来使用。
* 流式处理平台：Kafka提供了一个完整流式处理类库，比如窗口，连接，变换和聚合等操作。
### 消息系统使用场景
* 异步处理：非核心流程异步化，减少系统响应时间，提高吞吐量。例如：短信通知、终端状态推送、App推送、用户注册等。
* 系统解耦：系统之间不是强耦合的，消息接受者可以随意增加，而不需要修改消息发送者的代码。消息发送者的成功不依赖消息接受者（比如：有些银行接口不稳定，但调用方并不需要依赖这些接口）。
* 最终一致性：最终一致性不是消息队列的必备特性，但确实可以依靠消息队列来做最终一致性的事情。先写消息再操作，确保操作完成后再修改消息状态。定时任务补偿机制实现消息可靠发送接收、业务操作的可靠执行，要注意消息重复与幂等设计。所有不保证 100% 不丢消息 的消息队列，理论上无法实现 最终一致性。
* 流量削峰：当上下游系统处理能力存在差距的时候，利用消息队列做一个通用的“漏斗”，进行限流控制。在下游有能力处理的时候，再进行分发。
* 日志处理：将消息队列用在日志处理中，比如Kafka的应用，解决海量日志传输和缓冲的问题。

## Kafka中的ISR、AR又代表什么？ISR的伸缩又指什么
`AR=ISR+OSR`
* ISR: in-sync replicas，和leader副本保持在可接受滞后范围的副本列表
* OSR：out-of-sync replicas，与leader副本同步滞后过多的副本列表
* AR: asigned replicas，所有副本列表
### ISR伸缩
ISR伸缩指的是ISR集合副本数量的扩张和收缩。kafka在启动时会开启两个和ISR相关的任务，`isr-expiration`和`isr-change-propagation`，`isr-expiration`任务周期性的检测每个分区是否需要缩减其ISR集合，当检测到ISR集合中有失效副本时，就会收缩ISR集合。同样，随着follower副本不断与leader副本进行消息同步，follower副本的LEO会逐渐后移，并最终赶上leader副本（LEO不小于leader副本的HW），此时，follower副本可以加入ISR集合。当ISR集合发生增减、或者ISR集合的任一副本的LEO发生变化时，都会影响整个分区的HW。`isr-change-propagation`任务周期性检查`isrChangeSet`，当发现有ISR集合变更记录，就会在Zookeeper的`/isr_change_notification`路径下创建以`_isr_change_`开头的持久顺序节点，Kafka控制器监听该节点并向它管理的broker节点发送变更元数据的请求。
#### 失效副本
失效副本判定两个参数：
* replica.lag.max.messages：当follower副本滞后leader副本消息数超过该参数时，则判定为失效
* replica.lag.time.max.ms：当follower副本上一次将leader副本LEO之前的日志全部同步时的lastCaughtUpTimeMs值大于该参数时，则判定为失效

一般产生原因有：
* follower副本进程卡住，在一段时间内根本没有向leader副本发起同步请求，比如频繁的FullGC
* follower副本进程同步过慢，在一段时间内都无法追赶上leader副本，比如IO开销过大

## Kafka中的HW、LEO、LSO、LW等分别代表什么？
* HW：High Watermark，俗称高水位，它标识一个特定的消息偏移量（offset），消费者只能拉取到这个offset之前的消息。
* LEO：Log End Offset，它标识当前日志文件中下一条代写入消息的offset，相当于当前日志分区中最后一条消息的offset+1，分区ISR集合中每个副本都会维护自身的LEO，而ISR集合中最小的LEO及为分区的HW，而消费者也只能消费HW之前的消息。
* LSO：Last Stable Offset，对未完成的事务而言，LSO的值等于事务中第一条消息的位置(firstUnstableOffset)，对已完成的事务而言，它的值同HW相同。`LSO<=HW<=LEO`
* LW：Low Watermark，低水位，代表AR集合中最小的LogStartOffset值

## Kafka中是怎么体现消息顺序性的？
Kafka的消息有序通过offset体现的，offset是消息在分区中的唯一标识，Kafka通过offset保证消息在分区内的有序性，但是offset不能跨越分区，所以Kafka的消息有序性只体现在分区有序而不是主题有序。

值得一提的是，当acks参数为非0值，且max.in.flight.requests.per.connection参数为配置大于1的值时，那就有可能出现错序现象，比如第一批消息写入失败，第二批消息写入成功，生产者重试发送第一批消息写入成功，那么这两个批次的消息发送时就出现了错序。

## Kafka中分区器、序列化器、拦截器是否了解？它们之间的处理顺序是什么？
* 生产者顺序：拦截器->序列化器->分区器
* 消费者：反序列化器->拦截器
### 拦截器
#### 生产者拦截器
拦截器可以用来在消息发送前做一些准备工作，比如按照某个规则过滤不符合要求的消息、修改消息的内容等，也可以用来在发送回调逻辑前做一些定制化的需求，比如统计类工作。包含三个方法`onSend,onAcknowledgement,close`
* onSend：在消息序列化和计算分区之前调用
* onAcknowledgement：消息被应答之前或消息发送失败时调用
* close：关闭拦截器时执行一些资源的清理工作
#### 消费者拦截器
消费者拦截器也有三个方法`onConsume,onCommit,close`
* onConsume：在poll()方法返回之前调用，可以进行相应的定制化操作，比如修改返回的消息内容、按照某种规则过滤消息
* onCommit：提交完消费位移之后调用，可以用来记录跟踪所提交的位移信息
* close：关闭拦截器时执行一些资源的清理工作
### 序列化器&反序列化器
生产者需要用序列化器把对象转换成字节数组才能通过网络发送给Kafka，而在对侧，消费者需要用反序列化器把从Kafka中收到的字节数组转换成相应的对象。生产者使用的序列化器和消费者使用的反序列化器是需要一一对应的。序列化器包含三个方法`configure,serialize,close`，反序列化器包含三个方法`configure,deserialize,close`
### 分区器
消息经过序列化之后就需要确定它发往的分区，如果消息ProducerRecord中指定了partition字段，那么就不需要分区器的作用，因为partition代表的就是所要发往的分区号。如果消息ProducerRecord中没有指定partition字段，那么就需要依赖分区器。如果key值不为null，分区器会对key进行hash，根据最终得到的hash值来计算分区号；如果key为null，那么Producer将会把这条消息发送给随机的一个Partition。分区器包含三个方法`configure,partition,close`

## Kafka生产者客户端的整体结构是什么样子的？
整个生产者客户端由主线程、发送线程两个线程协调运行。KafkaProducer在主线程中创建消息，然后通过拦截器、序列化器、分区器作用之后缓存到消息累积器（RecordAccumulator），发送线程负责从消息累积器中获取消息并将其发送到Kafka中。
### 消息累积器（RecordAccumulator）
消息累积器主要用来缓存消息以便发送线程可以批量发送，进而减少网络传输的资源消耗以提升性能。缓存大小由客户端参数`buffer.memory`控制，默认为32MB。如果生产者发送消息的速度超过发送到服务器的速度，则会导致生产者空间不足，这时，KafkaProducer调用send()方法要么被阻塞，要么抛出异常。

消息累积器为每个分区维护一个双端队列，队列内容是ProducerBatch，消息写入缓存时，追加到双端队列尾部。发送线程从队列头部读取ProducerBatch。ProducerBatch表示一个消息批次，可以包含一个到多个ProducerRecord，这样可以使字节的使用更加紧凑，同时，将较小的ProducerRecord拼凑成一个较大的ProducerBatch，这样可以减少网络请求次数以提升整体吞吐量。

在消息累积器内部还使用了BufferPool来实现ByteBuffer的复用，避免频繁的内存申请和释放。由参数`batch.size`指定大小。

发送线程从消息累积器中获取缓存的消息后，会进一步将原本`<Partition, Deque<ProducerBatch>>`的保存形式转变成`<Node, List<ProducerBatch>>`的形式。因为对于网络连接来说，生产者客户端是与具体的broker节点建立连接，并不关心消息属于哪一个分区；而对于KafkaProducer的应用逻辑而言，只关注向哪个分区发送消息，所以，这里做了一个应用逻辑层面到网络IO层面的转换。

## Kafka的旧版Scala的消费者客户端的设计有什么缺陷？
旧版消费者基于Zookeeper的Watcher来实现功能，每个消费者对相关的路径进行监听，当触发再均衡操作时，一个消费者组下的所有消费者会同时进行在均衡操作，而消费者之间并不知道彼此操作的结果，可能会导致Kafka工作在一个不正确的状态。与此同时，过度依赖Zookeeper集群还有羊群效应、脑裂两个问题：
* 羊群效应：Zookeeper中一个被监听的节点变化，大量的Watcher事件通知被发送到客户端，导致在通知期间的其他操作延迟，也可能发生死锁问题。
* 脑裂问题：消费者再均衡操作时，每个消费者都与Zookeeper进行通信以判断消费者或Broker变化的情况，由于Zookeeper本身的特性，可能导致同一时刻的消费者获取的状态不一致。

## “消费组中的消费者个数如果超过topic的分区，那么就会有消费者消费不到数据”这句话是否正确？如果不正确，那么有没有什么hack的手段？
不正确。自定义分区分配策略使一个分区可以分配给多个消费者消费

## 消费者提交消费位移时提交的是当前消费到的最新消息的offset还是offset+1?
当前消费者需要提交的offset并不是offset，而是offset+1，它标识下一条需要拉取消息的位置

## 有哪些情形会造成重复消费？
一次拉取多条消息，消息全部处理完成再进行位移提交。若消费者在处理了部分消息之后异常宕机，则此时没有进行位移提交，故障恢复后消费者再次拉取的消息还是从宕机前最后一次提交的offset开始。则会产生重复消费消息。

## 那些情景下会造成消息漏消费？
一次拉取多条消息，拉取消息之后马上进行了位移提交。消费者在处理了部分消息之后异常宕机，故障恢复之后拉取到的是已经位移提交之后的值，未处理的消息则被漏消费（漏处理）。

## KafkaConsumer是非线程安全的，那么怎么样实现多线程消费？
KafkaConsumer定义了一个acquire方法，用来检查当前是否只有一个线程在操作，若有其他线程正在操作此KafkaConsumer，则会抛出ConcurrentModifcationException异常
* 每一个消费线程单独持有一个KafkaConsumer对象，但是此方法线程数受限于分区的实际个数。
* 单线程接收消息，多线程处理消息，但此方法会导致消息无法顺序处理，手动位移提交需要特别设计。

## 简述消费者与消费组之间的关系
* 若所有的消费者都属于同一个消费组，那么所有的消息都会被均衡的投递给每一个消费者，即每条消息只会被一个消费者处理，这就相当于“点对点”模式的应用
* 若所有的消费者都隶属于不同的消费组，那么所有的消息都会被广播给所有的消费者，即每条消息都会被所有的消费者处理，这就相当于“发布/订阅”模式的应用

## 当你使用kafka-topics.sh创建（删除）了一个topic之后，Kafka背后会执行什么逻辑？
### 创建topic
1. 在zookeeper的路径`/brokers/topics/{topic-name}`创建与待创建主题同名的节点。
2. kafka控制器监听到该节点变化，读取并检查新建主题的配置信息，比如主题名称是否合法，然后执行分区副本分配，在对应broker下log.dir或者log.dirs参数所配置的目录下创建相应的主题分区
### 删除topic
1. 在ZooKeeper的路径`/admin/delete_topics`创建与待删除主题同名的节点。
2. kafka控制器监听到该节点变化，判断该主题是否存在且可以删除，删除与zookeeper中该主题相关的节点和broker中对应的日志文件。

## topic的分区数可不可以增加？如果可以怎么增加？如果不可以，那又是为什么？
可以增加。通过`topic-topic.sh`脚本中的alter命令执行分区增加操作。值得注意的是，当分区数变化时，生产者中的分区器根据key计算分区的行为就会受到影响。

## topic的分区数可不可以减少？如果可以怎么减少？如果不可以，那又是为什么？
不可以减少。实现该功能需要考虑很多因素，比如待删除的分区中消息如何处理，消息的顺序性、事务性，分区和副本的状态机如何转换。这会使得代码复杂度急剧增加。而且，通过重新创建一个分区数较小的主题，将现有主题中的消息按照既定逻辑复制过去也可以实现此功能。

## 创建topic时如何选择合适的分区数？
分区数的选择视具体情况而定。增加合适的分区数可以在一定程度上提升整体的吞吐量，但超过对应的阈值之后吞吐量不升反降，建议在生产环境中做一个完备的测试找到合适分区数与阈值。一般情况下，根据预估的吞吐量及是否与key相关的规则来设定分区数即可，后期可以通过增加分区数、增加broker或分区重分配等手段来进行改进。如果一定要给一个准则，则建议将分区数设定为集群中broker的倍数，即假定集群中有3个broker节点，可以设定分区数为3、6、9等，至于倍数的选定可以参考预估的吞吐量。不过，如果集群中的broker节点数有很多，比如大几十或上百、上干，那么这种准则也不太适用，在选定分区数时进一步可以引入基架等参考因素。
### 分区数过多带来的问题
* 占用过多的系统资源，比如文件描述符，影响kafka正常启动与关闭耗时
* 影响系统可用性。当多个分区的leader副本被分配到同一个broker节点且该broker节点宕机时，就会有大量的分区需要同时进行leader角色切换，这个过程将会耗费一定的时间，而在这个时间窗口这些分区将处于不可用状态。

## Kafka目前有那些内部topic，它们都有什么特征？各自的作用又是什么？
* __consumer_offsets：用于存放存放消费者偏移量
* __transcation_state：用于持久化事务状态信息。

## 优先副本是什么？它有什么特殊的作用？
优先副本是指在AR集合列表中第一个副本。理想情况下，优先副本就是该分区的leader副本，Kafka会确保所有的主题的优先副本在集群中均匀分布。
### 优先副本的选举
优先副本的选举是指通过一定的方式促使优先副本选举为leader副本，以此来促进集群的负载均衡，这一行为也可以称为“分区平衡”。kafka提供分区自动平衡的功能，参数`auto.leader.rebalance.enable`，默认为true，即开启状态。当开启自动平衡功能时，kafka控制器将启动一个定时任务，轮询所有broker节点并计算broker节点的分区不平衡率是否超过`leader.imbalance.per.broker.percentage`参数的配置，如果超过则会自动执行优先副本的选举动作以求分区平衡。
### 是否应该开启自动平衡功能
* 分区平衡不代表负载均衡，生产环境不建议将`auto.leader.rebalance.enable`置为true，避免关键时候执行优先副本选举造成业务超时阻塞，因为leader副本转移是一件高成本的事情
* 在实际生产环境中，一般使用`path-to-json-file`参数来分批、手动地执行优先副本的选举操作。尤其是在应对大规模的Kafka集群时，理应杜绝采用非`path-to-json-file`参数的选举操作方式。同时，优先副本的选举操作也要注意避开业务高峰期，以免带来性能方面的负面影响 。

## Kafka有哪几处地方有分区分配的概念？简述大致的过程及原理、
### 生产者
生产者的分区分配是指为每条消息指定其所要发往的分区
### 消费者
为消费者指定其可以消费消息的分区
### kafka集群
#### 主题创建
在哪个broker中创建哪些分区的副本，一个分区的所有副本必须分配到不同的broker节点上。有两种方式
##### 手动指定分区分配方案
##### `assignReplicasToBrokersRackUnaware`计算
一个随机的起始索引`startIndex`，相对于前一次分配的偏移量`nextReplicaShift`。同时满足以下任意一个条件的`broker`不能被添加到当前分区的副本列表之中：
* 如果此broker所在的机架中己经存在一个broker拥有该分区的副本，并且还有其他的机架中没有任何一个broker拥有该分区的副本。
* 如果此broker中己经拥有该分区的副本，并且还有其他broker中没有该分区的副本。
#### 分区重分配

## 简述Kafka的日志目录结构

Kafka中有那些索引文件？

如果我指定了一个offset，Kafka怎么查找到对应的消息？

如果我指定了一个timestamp，Kafka怎么查找到对应的消息？

聊一聊你对Kafka的Log Retention的理解

聊一聊你对Kafka的Log Compaction的理解

聊一聊你对Kafka底层存储的理解（页缓存、内核层、块层、设备层）

聊一聊Kafka的延时操作的原理

聊一聊Kafka控制器的作用

消费再均衡的原理是什么？（提示：消费者协调器和消费组协调器）

Kafka中的幂等是怎么实现的

Kafka中的事务是怎么实现的（这题我去面试6家被问4次，照着答案念也要念十几分钟，面试官简直凑不要脸。实在记不住的话...只要简历上不写精通Kafka一般不会问到，我简历上写的是“熟悉Kafka，了解RabbitMQ....”）

Kafka中有那些地方需要选举？这些地方的选举策略又有哪些？

失效副本是指什么？有那些应对措施？

多副本下，各个副本中的HW和LEO的演变过程

为什么Kafka不支持读写分离？

Kafka在可靠性方面做了哪些改进？（HW, LeaderEpoch）

Kafka中怎么实现死信队列和重试队列？

Kafka中的延迟队列怎么实现（这题被问的比事务那题还要多！！！听说你会Kafka，那你说说延迟队列怎么实现？）

Kafka中怎么做消息审计？

Kafka中怎么做消息轨迹？

Kafka中有那些配置参数比较有意思？聊一聊你的看法

Kafka中有那些命名比较有意思？聊一聊你的看法

Kafka有哪些指标需要着重关注？

怎么计算Lag？(注意read_uncommitted和read_committed状态下的不同)

Kafka的那些设计让它有如此高的性能？

Kafka有什么优缺点？

还用过什么同质类的其它产品，与Kafka相比有什么优缺点？

为什么选择Kafka?

在使用Kafka的过程中遇到过什么困难？怎么解决的？

怎么样才能确保Kafka极大程度上的可靠性？

聊一聊你对Kafka生态的理解

## 参考链接
* <https://mp.weixin.qq.com/s/I-YsRKcjcBv4eOop-jjO0A>
* <https://juejin.im/post/5b41fe36e51d45191252e79e>
* <https://www.dazhuanlan.com/2019/10/27/5db52fbab04aa/>