# MQ-kafka

## 什么是kafka
Kafka起初是由Linkedin公司采用Scala语言开发的一个多分区、多副本且基于ZooKeeper协调的分布式消息系统，现己被捐献给Apache基金会。目前Kafka已经定位为一个分布式流式处理平台，它以高吞吐、可持久化、可水平扩展、支持流数据处理等多种特性而被广泛使用。

## kafka的用途有那些，使用场景如何
### 用途
* 消息系统：kafka与其他消息中间件都具备系统解耦、流量削峰、异步处理、弹性伸缩等功能。同时，kafka还提供其他大多数消息中间件难以实现的消息顺序性保障和回溯消费的功能。
* 存储系统：kafka可将消息持久化到磁盘，且可以多副本存储，通过设置数据保留策略为”永久”来作为长期数据存储系统来使用。
* 流式处理平台：Kafka提供了一个完整流式处理类库，比如窗口，连接，变换和聚合等操作。
### 消息系统使用场景
* 异步处理：非核心流程异步化，减少系统响应时间，提高吞吐量。例如：短信通知、终端状态推送、App推送、用户注册等。
* 系统解耦：系统之间不是强耦合的，消息接受者可以随意增加，而不需要修改消息发送者的代码。消息发送者的成功不依赖消息接受者（比如：有些银行接口不稳定，但调用方并不需要依赖这些接口）。
* 最终一致性：最终一致性不是消息队列的必备特性，但确实可以依靠消息队列来做最终一致性的事情。先写消息再操作，确保操作完成后再修改消息状态。定时任务补偿机制实现消息可靠发送接收、业务操作的可靠执行，要注意消息重复与幂等设计。所有不保证 100% 不丢消息 的消息队列，理论上无法实现 最终一致性。
* 流量削峰：当上下游系统处理能力存在差距的时候，利用消息队列做一个通用的“漏斗”，进行限流控制。在下游有能力处理的时候，再进行分发。
* 日志处理：将消息队列用在日志处理中，比如Kafka的应用，解决海量日志传输和缓冲的问题。

## Kafka中的ISR、AR又代表什么？ISR的伸缩又指什么
`AR=ISR+OSR`
* ISR: in-sync replicas，和leader副本保持在可接受滞后范围的副本列表
* OSR：out-of-sync replicas，与leader副本同步滞后过多的副本列表
* AR: asigned replicas，所有副本列表
### ISR伸缩
ISR伸缩指的是ISR集合副本数量的扩张和收缩。kafka在启动时会开启两个和ISR相关的任务，`isr-expiration`和`isr-change-propagation`，`isr-expiration`任务周期性的检测每个分区是否需要缩减其ISR集合，当检测到ISR集合中有失效副本时，就会收缩ISR集合。同样，随着follower副本不断与leader副本进行消息同步，follower副本的LEO会逐渐后移，并最终赶上leader副本（LEO不小于leader副本的HW），此时，follower副本可以加入ISR集合。当ISR集合发生增减、或者ISR集合的任一副本的LEO发生变化时，都会影响整个分区的HW。`isr-change-propagation`任务周期性检查`isrChangeSet`，当发现有ISR集合变更记录，就会在Zookeeper的`/isr_change_notification`路径下创建以`_isr_change_`开头的持久顺序节点，Kafka控制器监听该节点并向它管理的broker节点发送变更元数据的请求。

## Kafka中的HW、LEO、LSO、LW等分别代表什么？
* HW：High Watermark，俗称高水位，它标识一个特定的消息偏移量（offset），消费者只能拉取到这个offset之前的消息。
* LEO：Log End Offset，它标识当前日志文件中下一条代写入消息的offset，相当于当前日志分区中最后一条消息的offset+1，分区ISR集合中每个副本都会维护自身的LEO，而ISR集合中最小的LEO及为分区的HW，而消费者也只能消费HW之前的消息。
* LSO：Last Stable Offset，对未完成的事务而言，LSO的值等于事务中第一条消息的位置(firstUnstableOffset)，对已完成的事务而言，它的值同HW相同。`LSO<=HW<=LEO`
* LW：Low Watermark，低水位，代表AR集合中最小的LogStartOffset值

## Kafka中是怎么体现消息顺序性的？
Kafka的消息有序通过offset体现的，offset是消息在分区中的唯一标识，Kafka通过offset保证消息在分区内的有序性，但是offset不能跨越分区，所以Kafka的消息有序性只体现在分区有序而不是主题有序。

值得一提的是，当acks参数为非0值，且max.in.flight.requests.per.connection参数为配置大于1的值时，那就有可能出现错序现象，比如第一批消息写入失败，第二批消息写入成功，生产者重试发送第一批消息写入成功，那么这两个批次的消息发送时就出现了错序。

## Kafka中分区器、序列化器、拦截器是否了解？它们之间的处理顺序是什么？
* 生产者顺序：拦截器->序列化器->分区器
* 消费者：反序列化器->拦截器
### 拦截器
#### 生产者拦截器
拦截器可以用来在消息发送前做一些准备工作，比如按照某个规则过滤不符合要求的消息、修改消息的内容等，也可以用来在发送回调逻辑前做一些定制化的需求，比如统计类工作。包含三个方法`onSend,onAcknowledgement,close`
* onSend：在消息序列化和计算分区之前调用
* onAcknowledgement：消息被应答之前或消息发送失败时调用
* close：关闭拦截器时执行一些资源的清理工作
#### 消费者拦截器
消费者拦截器也有三个方法`onConsume,onCommit,close`
* onConsume：在poll()方法返回之前调用，可以进行相应的定制化操作，比如修改返回的消息内容、按照某种规则过滤消息
* onCommit：提交完消费位移之后调用，可以用来记录跟踪所提交的位移信息
* close：关闭拦截器时执行一些资源的清理工作
### 序列化器&反序列化器
生产者需要用序列化器把对象转换成字节数组才能通过网络发送给Kafka，而在对侧，消费者需要用反序列化器把从Kafka中收到的字节数组转换成相应的对象。生产者使用的序列化器和消费者使用的反序列化器是需要一一对应的。序列化器包含三个方法`configure,serialize,close`，反序列化器包含三个方法`configure,deserialize,close`
### 分区器
消息经过序列化之后就需要确定它发往的分区，如果消息ProducerRecord中指定了partition字段，那么就不需要分区器的作用，因为partition代表的就是所要发往的分区号。如果消息ProducerRecord中没有指定partition字段，那么就需要依赖分区器。如果key值不为null，分区器会对key进行hash，根据最终得到的hash值来计算分区号；如果key为null，那么Producer将会把这条消息发送给随机的一个Partition。分区器包含三个方法`configure,partition,close`

## Kafka生产者客户端的整体结构是什么样子的？
整个生产者客户端由主线程、发送线程两个线程协调运行。KafkaProducer在主线程中创建消息，然后通过拦截器、序列化器、分区器作用之后缓存到消息累积器（RecordAccumulator），发送线程负责从消息累积器中获取消息并将其发送到Kafka中。
### 消息累积器（RecordAccumulator）
消息累积器主要用来缓存消息以便发送线程可以批量发送，进而减少网络传输的资源消耗以提升性能。缓存大小由客户端参数`buffer.memory`控制，默认为32MB。如果生产者发送消息的速度超过发送到服务器的速度，则会导致生产者空间不足，这时，KafkaProducer调用send()方法要么被阻塞，要么抛出异常。

消息累积器为每个分区维护一个双端队列，队列内容是ProducerBatch，消息写入缓存时，追加到双端队列尾部。发送线程从队列头部读取ProducerBatch。ProducerBatch表示一个消息批次，可以包含一个到多个ProducerRecord，这样可以使字节的使用更加紧凑，同时，将较小的ProducerRecord拼凑成一个较大的ProducerBatch，这样可以减少网络请求次数以提升整体吞吐量。

在消息累积器内部还使用了BufferPool来实现ByteBuffer的复用，避免频繁的内存申请和释放。由参数`batch.size`指定大小。

发送线程从消息累积器中获取缓存的消息后，会进一步将原本`<Partition, Deque<ProducerBatch>>`的保存形式转变成`<Node, List<ProducerBatch>>`的形式。因为对于网络连接来说，生产者客户端是与具体的broker节点建立连接，并不关心消息属于哪一个分区；而对于KafkaProducer的应用逻辑而言，只关注向哪个分区发送消息，所以，这里做了一个应用逻辑层面到网络IO层面的转换。

## Kafka的旧版Scala的消费者客户端的设计有什么缺陷？
工作状态不明确：旧版消费者基于Zookeeper的Watcher来实现功能，每个消费者对相关的路径进行监听，当触发再均衡操作时，一个消费者组下的所有消费者会同时进行在均衡操作，而消费者之间并不知道彼此操作的结果，可能会导致Kafka工作在一个不正确的状态。
### 过度依赖Zookeeper集群：
* 羊群效应：Zookeeper中一个被监听的节点变化，大量的Watcher事件通知被发送到客户端，导致在通知期间的其他操作延迟，也可能发生死锁问题。
* 脑裂问题：消费者再均衡操作时，每个消费者都与Zookeeper进行通信以判断消费者或Broker变化的情况，由于Zookeeper本身的特性，可能导致同一时刻的消费者获取的状态不一致。

## “消费组中的消费者个数如果超过topic的分区，那么就会有消费者消费不到数据”这句话是否正确？如果不正确，那么有没有什么hack的手段？
不正确。自定义分区分配策略使一个分区可以分配给多个消费者消费

## 消费者提交消费位移时提交的是当前消费到的最新消息的offset还是offset+1?
当前消费者需要提交的offset并不是offset，而是offset+1，它标识下一条需要拉取消息的位置

## 有哪些情形会造成重复消费？
* Rebalance：一个consumer正在消费一个分区的一条消息，还没有消费完，发生了rebalance(加入了一个consumer)，从而导致这条消息没有消费成功，rebalance后，另一个consumer又把这条消息消费一遍。
* 消费者端手动提交：如果先消费消息，再更新offset位置，导致消息重复消费。
* 消费者端自动提交：设置offset为自动提交，关闭kafka时，如果在close之前，调用 consumer.unsubscribe() 则有可能部分offset没提交，下次重启会重复消费。
* 生产者端：生产者因为业务问题导致的宕机，在重启之后可能数据会重发

## 那些情景下会造成消息漏消费？
* 自动提交：设置offset为自动定时提交，当offset被自动定时提交时，数据还在内存中未处理，此时刚好把线程kill掉，那么offset已经提交，但是数据未处理，导致这部分内存中的数据丢失。
* 生产者发送消息：发送消息设置的是fire-and-forget（发后即忘），它只管往 Kafka 中发送消息而并不关心消息是否正确到达。不过在某些时候（比如发生不可重试异常时）会造成消息的丢失。这种发送方式的性能最高，可靠性也最差。
* 消费者端：先提交位移，但是消息还没消费完就宕机了，造成了消息没有被消费。自动位移提交同理
* acks没有设置为all：如果在broker还没把消息同步到其他broker的时候宕机了，那么消息将会丢失

## KafkaConsumer是非线程安全的，那么怎么样实现多线程消费？
KafkaConsumer定义了一个acquire方法，用来检查当前是否只有一个线程在操作，若有其他线程正在操作此KafkaConsumer，则会抛出ConcurrentModifcationException异常
* 每一个消费线程单独持有一个KafkaConsumer对象，但是此方法线程数受限于分区的实际个数。
* 单线程接收消息，多线程处理消息，但此方法会导致消息无法顺序处理，手动位移提交需要特别设计。

## 简述消费者与消费组之间的关系
* 若所有的消费者都属于同一个消费组，那么所有的消息都会被均衡的投递给每一个消费者，即每条消息只会被一个消费者处理，这就相当于“点对点”模式的应用
* 若所有的消费者都隶属于不同的消费组，那么所有的消息都会被广播给所有的消费者，即每条消息都会被所有的消费者处理，这就相当于“发布/订阅”模式的应用

## 当你使用kafka-topics.sh创建（删除）了一个topic之后，Kafka背后会执行什么逻辑？
### 创建topic
1. 在zookeeper的路径`/brokers/topics/{topic-name}`创建与待创建主题同名的节点。
2. kafka控制器监听到该节点变化，读取并检查新建主题的配置信息，比如主题名称是否合法，然后执行分区副本分配，在对应broker下log.dir或者log.dirs参数所配置的目录下创建相应的主题分区
### 删除topic
1. 在ZooKeeper的路径`/admin/delete_topics`创建与待删除主题同名的节点。
2. kafka控制器监听到该节点变化，判断该主题是否存在且可以删除，删除与zookeeper中该主题相关的节点和broker中对应的日志文件。

## topic的分区数可不可以增加？如果可以怎么增加？如果不可以，那又是为什么？
可以增加。通过`topic-topic.sh`脚本中的alter命令执行分区增加操作。值得注意的是，当分区数变化时，生产者中的分区器根据key计算分区的行为就会受到影响。

## topic的分区数可不可以减少？如果可以怎么减少？如果不可以，那又是为什么？
不可以减少。因为删除的分区中的消息不好处理。如果直接存储到现有分区的尾部，消息的时间戳就不会递增，如此对于 Spark、Flink 这类需要消息时间戳（事件时间）的组件将会受到影响；如果分散插入现有的分区，那么在消息量很大的时候，内部的数据复制会占用很大的资源，而且在复制期间，此主题的可用性又如何得到保障？与此同时，顺序性问题、事务性问题，以及分区和副本的状态机切换问题都是不得不面对的。

## 创建topic时如何选择合适的分区数？
分区数的选择视具体情况而定。增加合适的分区数可以在一定程度上提升整体的吞吐量，但超过对应的阈值之后吞吐量不升反降，建议在生产环境中做一个完备的测试找到合适分区数与阈值。一般情况下，根据预估的吞吐量及是否与key相关的规则来设定分区数即可，后期可以通过增加分区数、增加broker或分区重分配等手段来进行改进。如果一定要给一个准则，则建议将分区数设定为集群中broker的倍数，即假定集群中有3个broker节点，可以设定分区数为3、6、9等，至于倍数的选定可以参考预估的吞吐量。不过，如果集群中的broker节点数有很多，比如大几十或上百、上干，那么这种准则也不太适用，在选定分区数时进一步可以引入基架等参考因素。
### 分区数过多带来的问题
* 占用过多的系统资源，比如文件描述符，影响kafka正常启动与关闭耗时
* 影响系统可用性。当多个分区的leader副本被分配到同一个broker节点且该broker节点宕机时，就会有大量的分区需要同时进行leader角色切换，这个过程将会耗费一定的时间，而在这个时间窗口这些分区将处于不可用状态。

## Kafka目前有那些内部topic，它们都有什么特征？各自的作用又是什么？
* __consumer_offsets：用于存放存放消费者偏移量
* __transcation_state：用于持久化事务状态信息。

## 优先副本是什么？它有什么特殊的作用？
优先副本是指在AR集合列表中第一个副本。理想情况下，优先副本就是该分区的leader副本，Kafka会确保所有的主题的优先副本在集群中均匀分布。
### 优先副本的选举
优先副本的选举是指通过一定的方式促使优先副本选举为leader副本，以此来促进集群的负载均衡，这一行为也可以称为“分区平衡”。kafka提供分区自动平衡的功能，参数`auto.leader.rebalance.enable`，默认为true，即开启状态。当开启自动平衡功能时，kafka控制器将启动一个定时任务，轮询所有broker节点并计算broker节点的分区不平衡率是否超过`leader.imbalance.per.broker.percentage`参数的配置，如果超过则会自动执行优先副本的选举动作以求分区平衡。
### 是否应该开启自动平衡功能
* 分区平衡不代表负载均衡，生产环境不建议将`auto.leader.rebalance.enable`置为true，避免关键时候执行优先副本选举造成业务超时阻塞，因为leader副本转移是一件高成本的事情
* 在实际生产环境中，一般使用`path-to-json-file`参数来分批、手动地执行优先副本的选举操作。尤其是在应对大规模的Kafka集群时，理应杜绝采用非`path-to-json-file`参数的选举操作方式。同时，优先副本的选举操作也要注意避开业务高峰期，以免带来性能方面的负面影响 。

## Kafka有哪几处地方有分区分配的概念？简述大致的过程及原理、
### 生产者
生产者的分区分配是指为每条消息指定其所要发往的分区
### 消费者
为消费者指定其可以消费消息的分区
### kafka集群
#### 主题创建
在哪个broker中创建哪些分区的副本，一个分区的所有副本必须分配到不同的broker节点上。有两种方式
##### 手动指定分区分配方案
##### `assignReplicasToBrokersRackUnaware`计算
一个随机的起始索引`startIndex`，相对于前一次分配的偏移量`nextReplicaShift`。同时满足以下任意一个条件的`broker`不能被添加到当前分区的副本列表之中：
* 如果此broker所在的机架中己经存在一个broker拥有该分区的副本，并且还有其他的机架中没有任何一个broker拥有该分区的副本。
* 如果此broker中己经拥有该分区的副本，并且还有其他broker中没有该分区的副本。
#### 分区重分配
集群负载不均衡的原因
* 节点宕机下线，如果该节点上的分区是多副本的，则位于该节点上的leader副本的角色会迁移到其他节点的follower副本上，即使该节点重新上线，也是以follower副本身份恢复
* 要对集群中的某一节点进行有计划的下线，为了保证分区及副本分配合理，期望通过某种方式能够将该节点的分区副本迁移到其他可用节点上
* 集群中新增broker节点，只有新创建的主题分区才有可能被分配到这个节点上

为了解决上述问题，需要让分区副本再次进行合理的分配，也就是分区重分配。kafka提供`kafka-reassign-partitions.sh`脚本执行分区重分配工作，可以在集群扩容，broker节点失效的场景下对分区进行迁移。`kafka-reassign-partitions.sh`脚本的使用分为3个步骤: 首先创建一个包含主题清单的JSON文件，其次根据主题清单和broker节点清单生成一份重分配方案，最后根据这份方案执行具体的重分配动作。

## 简述Kafka的日志目录结构
不考虑多副本的情况，一个分区对应一个日志(Log)。为了防止Log过大，Kafka又引入了日志分段(LogSegment)的概念，将Log切分为多个LogSegment，相当于一个巨型文件被平均分配为多个相对较小的文件，这样也便于消息的维护和清理。但是Log和LogSegnient并不是纯粹物理意义上的概念，Log在物理上只以文件夹的形式存储，以`<topic>-<partition>`的方式命名，而每个LogSegment对应于磁盘上的一个日志文件（`.log`）和两个索引文件（偏移量索引文件`.index`、时间戳索引文件`.timeindex`），文件名前缀为固定20位数字（没达到20位数字则用0填充）基准偏移量。只有最后一个LogSegament才能执行写入操作，即活跃的日志分段。随着消息的不断写入，当活跃的日志分段满足一定条件时，就需要创建新的活跃日志分段，之后追加的消息将写入新的活跃日志分段。
### 日志分段文件切分
日志文件需要切分时，其对应的索引文件也会被切分，满足以下任一条件即可。
* 当前日志分段文件的大小超过了broker端参数`log.segment.bytes`配置的值，默认为1GB
* 当前日志分段中消息的最大时间戳与当前系统的时间戳的差值大于`log.roll.ms`或`log.roll.hours`参数配置的值。如果同时配置了`log.roll.ms`和`log.roll.hours`参数，那么`log.roll.ms`的优先级高。
* 偏移量索引文件或时间戳索引文件的大小达到broker端参数`log.index.size.max.bytes`配置的值,默认为1OMB。
* 追加的消息的偏移量与当前日志分段的偏移量之间的差值大于`Integer.MAX_VALUE`，即要追加的消息的偏移量不能转变为相对偏移量(`offset - baseOffset > Integer.MAX_VALUE`)

## Kafka中有那些索引文件？
kafka每个日志分段对应两个索引文件，偏移量索引文件`.index`和时间戳索引文件`.timeindex`，偏移量索引文件用来建立消息偏移量(offset)到物理地址之间的映射关系，方便快速定位消息所在的物理文件位置;时间戳索引文件则根据指定的时间戳(timestamp)来查找对应的偏移量信息。

Kafka中的索引文件以稀疏索引(sparse index)的方式构造消息的索引，并不保证每个消息在索引文件中都有对应的索引项。每当写入一定量(由broker端参数`log.index.interval.bytes`指定，默认值为4096，即4KB)的消息时，偏移量索引文件和时间戳索引文件分别增加一个偏移量索引项和时间戳索引项，增大或减小`log.index.interval.bytes`的值，对应地可以增加或缩小索引项的密度。通过MappedByteBuffer可以将索引文件映射到内存中，加快索引的查询速度。

## 如果我指定了一个offset，Kafka怎么查找到对应的消息？
偏移量索引文件的每个索引项包含两部分，相对偏移量（relativeOffset，4字节）、物理地址（position，4字节）
1. 因为偏移量索引文件中的偏移量是单调递增的，在查询指定偏移量时，使用二分查找法来快速定位偏移量的位置，如果指定的偏移量不在索引文件中，则会返回小于指定偏移量的最大偏移量
2. 计算消息offset在偏移量索引文件中的相对偏移量，找到对应的索引项，找到对应的物理地址
3. 在日志分段文件中找到对应物理位置的消息

## 如果我指定了一个timestamp，Kafka怎么查找到对应的消息？
时间戳索引文件的每个索引项包含两部分，时间戳（timestamp，8字节）、相对偏移量（relativeOffset，4字节）
1. 时间戳索引文件中的时间戳也保持严格的单调递增，查询指定时间戳时，也根据二分查找法来查找不大于该时间戳的索引文件
2. 在时间戳索引文件中，找到时间戳不大于该指定时间戳的所影响，得到对应的相对偏移量。
3. 根据相对偏移量在偏移量索引文件中找到对应的索引项，找到对应的物理地址
4. 在日志分段文件中找到对应物理位置的消息

## 日志清理
kafka提供两种日志清理策略，即日志删除（Log Retention）、日志压缩（Log Compaction）。
### 聊一聊你对Kafka的Log Retention的理解
Log Retention即按照一定的保留策略直接删除不符合条件的日志分段。主要分为下面三种策略：
* 基于时间：日志删除任务会检查当前日志文件中是否有保留时间超过设定阈值的日志分段文件集合。阈值可以通过broker端参数`log.retention.hours`、`log.retention.minutes`和`log.retention.ms`来配置，优先级依次提高，默认为七天。
* 基于日志大小：日志删除任务会检查当前日志文件的总文件大小超过设定阈值。计算出需要删除的日志总大小，然后从日志文件的第一个日志分段查找可删除的日志分段集合，执行删除操作
* 基于日志起始偏移量：基于日志起始偏移量的保留策略的判断依据是某日志分段的下一个日志分段的起始偏移量baseOffset是否小于logStartOffset，若是则可以删除此日志分段。
### 聊一聊你对Kafka的Log Compaction的理解
日志压缩即有相同key，但是value不同的消息，只保留最后一个版本。日志压缩需要做两次遍历操作，第一次把每个key的哈希值和最后出现的offset保存到SkimpyOffsetMap中，第二次遍历会检查每个消息是否符合保留条件，符合则保留下来。同时为了防止日志压缩后出现过多小文件，kafka在实际清理过程中并不对单个日志分段进行单独清理，而是将日志分段分组，同一个组的日志分段清理完成后，只会生成一个新的日志分段

## 聊一聊你对Kafka底层存储的理解（页缓存、内核层、块层、设备层）
### 磁盘顺序读写
一般来说，操作系统存储分为多级结构，从磁带、磁盘、主存、高速缓存到寄存器缓存，层级越高代表速度越快，价格也越昂贵。kafka依赖于磁盘存储来存储消息，采用文件追加的方式写入消息，即只能在日志文件尾部追加新的消息，并且也不允许修改已写入的消息，即kafka只按照顺序读写磁盘。操作系统针对顺序读写方式做了优化，包括预读（read-ahead）、后写（write-behind）技术。测试结果表示，顺序写盘速度不仅比随机写盘速度快，也比随机写内存的速度快。
### 操作系统页缓存
kafka采用了大量的页缓存技术，这也是kafka实现高吞吐的重要因素之一。页缓存是操作系统实现磁盘缓存中重要的一种方式，以此用来减少对磁盘I/O的操作。具体来说，就是把磁盘中的数据缓存到内存中，把对磁盘的访问改变为对内存的访问。当一个进程准备读取磁盘上的文件内容时，操作系统会先查看待读取的数据所在的页(page)是否在页缓存(pagecache)中，如果存在(命中〉则直接返回数据，从而避免了对物理磁盘的I/O操作;如果没有命中，则操作系统会向磁盘发起读取请求并将读取的数据页存入页缓存，之后再将数据返回给进程。同样，如果一个进程需要将数据写入磁盘，那么操作系统也会检测数据对应的页是否在页缓存中，如果不存在，则会先在页缓存中添加相应的页，最后数据写入对应的页。被修改过后的页也就变成了脏页，操作系统会在合适的时间把脏页中的数据写入磁盘，以保持数据的一致性。
### 操作系统零拷贝
除了消息顺序追加、页缓存等技术，Kafka还使用零拷贝（Zero-Copy）技术来进一步提升性能。所谓的零拷贝是指将数据直接从磁盘文件复制到网卡设备中，而不需要经由应用程序之手。零拷贝大大提高了应用程序的性能，减少了内核和用户模式之间的上下文切换。在Linux操作系统中，零拷贝技术依赖于底层的sendfile()方法实现。

## 聊一聊Kafka的延时操作的原理
延时操作即由于当前时间点得不到响应结果，需要延时等待，在一个超时时间范围内，能够由外部事件触发完成；如果超时时间过后没有完成既定的任务，则强制返回一个响应结果给客户端 。Kafka中有多种延时操作，比如延时生产，还有延时拉取。延时操作在创建之后会被加入延时操作管理器来做专门的处理。因为延时操作有可能会超时，所以管理器会给每个延时配置一个定时器（SystemTimer）来做超时管理，定时器的底层就是采用时间轮（TimingWheel）实现。同时，延时操作需要支持外部事件的触发，所以还有一个监听池来负责监听每个分区的外部事件。收割机线程`ExpiredOperationReaper`不仅会推进时间轮，还会定期清理监听池中已完成的延时操作。
### 延时生产
当设置`acks=-1`，则意味着生产者需要等待ISR集合中所有的副本都确认收到消息之后才能正确的收到响应的结果，或者捕获超时异常。kafka将消息写入leader副本的本地日志文件后，将创建一个延时的生产操作。延时生产操作的外部事件是某个分区的HW发生增长。
### 延时拉取
在一次拉取请求中，会先读取一次日志文件，如果收集不到足够多的消息，则会创建一个延时拉取操作以等待足够数量的消息。如果是follower副本的拉取，外部事件即为有新消息追加到leader副本的日志文件中；如果是消费者客户端的拉取，外部事件即为分区HW的增长。

## 聊一聊Kafka控制器的作用
在Kafka集群中会有一个或多个broker，其中有一个broker会被选举为控制器（Kafka Controller），它负责管理整个集群中所有分区和副本的状态。具体细节如下：
* 监听分区相关变化，处理ISR伸缩，优先副本选举，分区重分配
* 监听主题相关变化，处理主题的创建和删除
* 监听broker相关变化，处理broker节点的增减

## 消费再均衡的原理是什么？（提示：消费者协调器和消费组协调器）
### 触发再均衡的场景
* 有新的消费者加入消费组。
* 有消费者宕机下线。消费者并不一定需要真正下线，例如遇到长时间的GC、网络延迟导致消费者长时间未向GroupCoordinator发送心跳等情况时，GroupCoordinator会认
为消费者己经下线。
* 有消费者主动退出消费组（发送LeaveGroupRequest请求。比如客户端调用了unsubscrible()方法取消对某些主题的订阅。
* 消费组所对应的GroupCoorinator节点发生了变更。
* 消费组内所订阅的任一主题或者主题的分区数量发生变化。
### 再均衡阶段
kafka将全部消费组分成多个子集，每个消费组的子集在服务端对应一个组协调器（GroupCoordinator）对其进行管理，GroupCoordinator是Kafka服务端中用于管理消费组的组件。而消费者客户端中的消费者协调器（ConsumerCoordinator）组件负责与消费组协调器（GroupCoordinator）进行交互。具体分为四个阶段
#### 第一阶段：找到消费者协调器（Find GroupCoordinator）
消费者需要确定它所属的消费组对应的GroupCoordinator所在的broker，并创建与该broker相互通信的网络连接。如果消费者已经保存了与消费组对应的GroupCoordinator节点的信息，并且与它之间的网络连接是正常的，那么就可以进入第二阶段。否则，就需要向集群中的某个节点发送FindCoordinatorRequest请求来查找对应的GroupCoordinator，这里的“某个节点”并非是集群中的任意节点，而是负载最小的节点。kafka在收到FindCoordinatorRequest请求之后，根据groupID的哈希值计算__consumer_offsets中的分区号，再根据分区号找到此分区leader副本所在的broker节点。
#### 第二阶段：加入消费者组（Join Group）
在成功找到消费组所对应的`GroupCoordinator`之后就进入加入消费组的阶段，在此阶段的消费者会向`GroupCoordinator`发送`JoinGroupRequest`请求，GroupCoordinator会进行消费组leader选举，分区分配策略选举，向所有消费者返回响应，其中，只有leader消费者的响应体中包含了各个消费者的订阅信息。
##### 组协调器节点选举消费组的leader
如果消费组内还没有`leader`,即消费者协调器，那么第一个加入消费组的消费者即为消费组的`leader`。如果某一时刻`leader`消费者由于某些原因退出了消费组，那么会重新选举一个新的`leader`
##### 选举分区分配策略
1. 收集各个消费者支持的所有分配策略，组成候选集 candidates。
2. 每个消费者从候选集 candidates 中找出第一个自身支持的策略，为这个策略投上一票。
3. 计算候选集中各个策略的选票数，选票数最多的策略即为当前消费组的分配策略。
#### 第三阶段：分区分配策略同步（Sync Group）
所有的消费者都向GroupCoordinator发送`SyncGroupRequest`，只有leader消费者发送的请求中包含了分区分配方案，`GroupCoordinator`向各个消费者响应对应的分区结果。
#### 第四阶段：心跳（HeartBeat）
消费者通过向`GroupCoordinator`发送心跳来维持它们与消费组的从属关系，以及它们对分区的所有权关系。只要消费者以正常的时间间隔发送心跳，就被认为是活跃的，说明它还在读取分区中的消息。心跳线程是一个独立的线程，可以在轮询消息的空档发送心跳。如果消费者停止发送心跳的时间足够长，则整个会话就被判定为过期,`GroupCoordinator`也会认为这个消费者己经死亡，就会触发一次再均衡行为。 

## Kafka中的幂等是怎么实现的
### 消息传输保障
一般而言，消息中间件的消息传输保障有3个层级，分别如下。
1. `at most once`：至多一次。消息可能会丢失，但绝对不会重复传输。
2. `at least once`： 最少一次。消息绝不会丢失，但可能会重复传输。
3. `exactly once`：恰好一次。每条消息肯定会被传输一次且仅传输一次。

Kafka 的消息传输保障机制非常直观。当生产者向Kafka发送消息时，一旦消息被成功提交到日志文件，由于多副本机制的存在，这条消息就不会丢失。如果生产者发送消息到Kafka之后，遇到了网络问题而造成通信中断，那么生产者就无法判断该消息是否己经提交。虽然Kafka无法确定网络故障期间发生了什么，但生产者可以进行多次重试来确保消息已经写入Kafka,这个重试的过程中有可能会造成消息的重复写入，所以这里Kafka提供的消息传输保障为`at least once`。
### 幂等实现
kafka实现的幂等是单分区单会话的幂等，引入了`producer id`（以下简称PID）和`sequence number`这两个概念。

每个新的生产者实例在初始化的时候都会被分配一个 PID，这个PID对用户而言是完全透明的。对于每个PID，消息发送到的每一个分区都有对应的序列号，这些序列号从0开始单调递增。生产者每发送一条消息就会将`<PID，分区>`对应的序列号的值加1。

服务端会在内存中为每一对`<PID，partition>`维护一个序列号。对于收到的每一条消息，只有当它的序列号的值（SN_new）比服务端中维护的对应的序列号的值（SN_old）大1（即`SN_new = SN_old + 1`）时，服务端才会接收它。如果`SN_new< SN_old + 1`，那么说明消息被重复写入，服务端可以直接将其丢弃。如果`SN_new> SN_old + 1`，那么说明中间有数据尚未写入，出现了乱序，暗示可能有消息丢失，对应的生产者会抛出异常。

## Kafka中有那些地方需要选举？这些地方的选举策略又有哪些？
### 控制器选举
在Kafka集群中会有一个或多个broker，其中有一个broker会被选举为控制器（Kafka Controller），它负责管理整个集群中所有分区和副本的状态等工作。比如当某个分区的leader副本出现故障时，由控制器负责为该分区选举新的leader副本。再比如当检测到某个分区的ISR集合发生变化时，由控制器负责通知所有broker更新其元数据信息。

`Kafka Controller`的选举是依赖Zookeeper来实现的，在Kafka集群中哪个broker能够成功创建/controller这个临时（EPHEMERAL）节点他就可以成为Kafka Controller。
### 分区leader选举
分区leader副本的选举由`Kafka Controller`负责具体实施。比如创建分区、分区leader下线、分区重分配等，基本思路是按照AR集合中副本的顺序查找第一个存活的副本，并且这个副本在ISR集合中。一个分区的AR集合在分配的时候就被指定，并且只要不发生重分配的情况，集合内部副本的顺序是保持不变的，而分区的ISR集合中副本的顺序可能会改变。

还有一种情况是优先副本（preferred replica partition leader election）的选举时，直接将优先副本设置为leader即可，AR集合中的第一个副本即为优先副本。
### 消费组leader选举
如果消费组内还没有leader，那么第一个加入消费组的消费者即为消费组的leader。如果某一时刻leader消费者由于某些原因退出了消费组，那么会重新选举一个新的leader，选举过程基本上和随机无异。

## 失效副本是指什么？有那些应对措施？
正常情况下，分区的所有副本都处于ISR集合中，但是难免会有异常情况发生，从而某些副本被剥离出ISR集合中。在ISR集合之外，也就是处于同步失效或功能失效（比如副本处于非存活状态）的副本统称为失效副本，失效副本对应的分区也就称为同步失效分区，即`under-replicated`分区。失效副本判定两个参数：
* replica.lag.max.messages：当follower副本滞后leader副本消息数超过该参数时，则判定为失效
* replica.lag.time.max.ms：当follower副本上一次将leader副本LEO之前的日志全部同步时的lastCaughtUpTimeMs值大于该参数时，则判定为失效

一般产生原因有：
* follower副本进程卡住，在一段时间内根本没有向leader副本发起同步请求，比如频繁的FullGC
* follower副本进程同步过慢，在一段时间内都无法追赶上leader副本，比如IO开销过大
* 如果通过工具增加了副本因子，那么新增加的副本在赶上 leader 副本之前也都是处于失效状态的。
* 如果一个`follower`副本由于某些原因（比如宕机）而下线，之后又上线，在追赶上`leader`副本之前也处于失效状态。

### 应对措施
我们用UnderReplicatedPartitions代表leader副本在当前Broker上且具有失效副本的分区的个数。

如果集群中有多个Broker的UnderReplicatedPartitions保持一个大于0的稳定值时，一般暗示着集群中有Broker已经处于下线状态。这种情况下，这个Broker中的分区个数与集群中的所有UnderReplicatedPartitions（处于下线的Broker是不会上报任何指标值的）之和是相等的。通常这类问题是由于机器硬件原因引起的，但也有可能是由于操作系统或者JVM引起的 。

如果集群中存在Broker的UnderReplicatedPartitions频繁变动，或者处于一个稳定的大于0的值（这里特指没有Broker下线的情况）时，一般暗示着集群出现了性能问题，通常这类问题很难诊断，不过我们可以一步一步的将问题的范围缩小，比如先尝试确定这个性能问题是否只存在于集群的某个Broker中，还是整个集群之上。如果确定集群中所有的under-replicated分区都是在单个Broker上，那么可以看出这个Broker出现了问题，进而可以针对这单一的Broker做专项调查，比如：操作系统、GC、网络状态或者磁盘状态（比如：iowait、ioutil等指标）。

## 多副本下，各个副本中的HW和LEO的演变过程
1. 生产者客户端发送消息至`leader`副本中。
2. 消息被追加到`leader`副本的本地日志，并且会更新日志的偏移量LEO。
3. `follower`副本向`leader`副本请求同步数据，带有自身LEO信息
4. `leader`副本所在的服务器读取本地日志，并更新对应拉取的`follower`副本的信息，更新自身HW信息。
5. `leader`副本所在的服务器将拉取结果返回给`follower`副本。
6. `follower`副本收到`leader`副本返回的拉取结果，将消息追加到本地日志中，并自身LEO和HW。

## 为什么Kafka不支持读写分离？
因为这样有两个明显的缺点：
* 数据一致性问题：数据从主节点转到从节点必然会有一个延时的时间窗口，这个时间窗口会导致主从节点之间的数据不一致。
* 延时问题：数据从写入主节点到同步至从节点中的过程需要经历网络→主节点内存→主节点磁盘→网络→从节点内存→从节点磁盘这几个阶段。对延时敏感的应用而言，主写从读的功能并不太适用。

对于Kafka来说，必要性不是很高，因为在Kafka集群中，如果存在多个副本，经过合理的配置，可以让leader副本均匀的分布在各个broker上面，实现broker的读写负载均衡。

## Kafka在可靠性方面做了哪些改进？（HW, LeaderEpoch）
`leader epoch`代表leader的纪元信息（epoch），初始值为0。每当 leader 变更一次，`leader epoch`的值就会加1，相当于为leader增设了一个版本号。每个副本中还会增设一个矢量`<LeaderEpoch => StartOffset>`，其中`StartOffset`表示当前`LeaderEpoch`下写入的第一条消息的偏移量。leader副本在收到follower副本的`OffsetsForLeaderEpochRequest`请求时，会先比较`leader epoch`是否一致，如果不一致，则leader副本将当前`leader epoch`对应的`startOffset`返回给follower副本，避免了leader副本和follower副本数据不一致性问题。

## Kafka中怎么实现死信队列和重试队列？
死信可以看作消费者不能处理收到的消息，也可以看作消费者不想处理收到的消息，还可以看作不符合处理要求的消息。比如消息内包含的消息内容无法被消费者解析，为了确保消息的可靠性而不被随意丢弃，故将其投递到死信队列中，这里的死信就可以看作消费者不能处理的消息。再比如超过既定的重试次数之后将消息投入死信队列，这里就可以将死信看作不符合处理要求的消息。

重试队列其实可以看作一种回退队列，具体指消费端消费消息失败时，为了防止消息无故丢失而重新将消息回滚到broker中。与回退队列不同的是，重试队列一般分成多个重试等级，每个重试等级一般也会设置重新投递延时，重试次数越多投递延时就越大，并且需要设置一个上限，超过投递次数就进入死信队列。重试队列与延时队列有相同的地方，都需要设置延时级别。

## Kafka中的延迟队列怎么实现（这题被问的比事务那题还要多！！！听说你会Kafka，那你说说延迟队列怎么实现？）
### 方式一：延时主题（有一定的时间误差）
发送延时消息的时候并不是先投递到要发送的真实主题(real_topic)中，而是先投递到一些`Kafka`内部的主题(delay topic)中，这些内部主题对用户不可见，然后通过一个自定义的服务拉取这些内部主题中的消息，并将满足条件的消息再投递到要发送的真实的主题中，消费者所订阅的还是真实的主题。

采用这种方案，一般是按照不同的延时等级来划分的(因为按秒级划分太浪费资源了)，比如设定5s、10s、30s、1min、2min、5min、10min、20min、30min、45min、1hour、2hour这些按延时时间递增的延时等级，延时的消息按照延时时间投递到不同等级的主题中，投递到同一主题中的消息的延时时间会被强转为与此主题延时等级一致的延时时间，这样延时误差控制在两个延时等级的时间差范围之内。虽然有一定的延时误差，但是误差可控，并且这样只需增加少许的主题就能实现延时队列的功能。

发送到内部主题（delay_topic_*）中的消息会被一个独立的DelayService进程消费，针对不同延时级别的主题，在DelayService的内部都会有单独的线程来进行消息的拉取，以及单独的`DelayQueue`进行消息的暂存。与此同时，在`DelayService`内部还会有专门的消息发送线程来获取`DelayQueue`的消息并转发到真实的主题中。从消费、暂存再到转发，线程之间都是一一对应的关系。因为一个主题中一般不止一个分区，分区之间的消息并不会按照投递时间进行排序，DelayQueue的作用是将消息按照再次投递时间进行有序排序，这样下游的消息发送线程就能够按照先后顺序获取最先满足投递条件的消息。
### 方式二：单层时间轮（实现复杂）
时间轮中每个时间格代表一个延时时间， 并且每个时间格也对应一个文件，整体上可以看作单层文件时间轮。
假设每个时间格代表1秒，若要支持2小时(也就是`2×60×60=7200`)之内的延时时间的消息，那么整个单层时间轮的时间格数就需要7200个，与此对应的也就需要7200个文件，听上去似乎需要庞大的系统开销，就单单文件句柄的使用也会耗费很多的系统资源。其实不然，我们并不需要维持所有文件的文件句柄，只需要加载距离时间轮表盘指针(currentTime)相近位置的部分文件即可，其余都可以用类似“懒加载”的机制来维持:若与时间格对应的文件不存在则可以新建，若与时间格对应的文件未加载则可以重新加载，整体上造成的时延相比于延时等级方案而言微乎其微。随着表盘指针的转动，其相邻的文件也会变得不同，整体上在内存中只需要维持少量的文件句柄就可以让系统运转起来。
### 方式三：数据库(mysql、redis）+定时任务

## Kafka中怎么做消息审计？
消息审计是指在消息生产、存储和消费的整个过程之间对消息个数及延迟的审计，以此来检测是否有数据丢失、是否有数据重复、端到端的延迟又是多少等内容。目前与消息审计有关的产品也有多个，主要通过在消息体（value 字段）或在消息头（headers字段）中内嵌消息对应的时间戳timestamp或全局的唯一标识ID或者是两者兼备来实现消息的审计功能。
内嵌timestamp可以统计端到端消息延迟，内嵌ID可以判断出哪条消息丢失、哪条消息重复。可以把消息审计看作粗粒度的消息轨迹。

## Kafka中怎么做消息轨迹？
消息轨迹指的是一条消息从生产者发出，经由`broker`存储，再到消费者消费的整个过程中，各个相关节点的状态、时间、地点等数据汇聚而成的完整链路信息。生产者、broker、消费者这3个角色在处理消息的过程中都会在链路中增加相应的信息，将这些信息汇聚、处理之后就可以查询任意消息的状态，进而为生产环境中的故障排除提供强有力的数据支持。对消息轨迹而言，最常见的实现方式是封装客户端，在保证正常生产消费的同时添加相应的轨迹信息埋点逻辑。无论生产，还是消费，在执行之后都会有相应的轨迹信息，我们需要将这些信息保存起来。

## Kafka有哪些指标需要着重关注？
* BytesIn/BytesOut：即Broker端每秒流入、流出字节数。你要确保这组值不要接近你的网络带宽，否则这通常都表示网卡已被“打满”，很容易出现网络丢包的情形。
* ISRShrink/ISRExpand：即ISR收缩和扩容的频次指标。如果你的环境中出现ISR中副本频繁进出的情形，那么这组值一定是很高的。这时，你要诊断下副本频繁进出ISR的原因，并采取适当的措施。
* UnderReplicatedPartitions：即未充分备份的分区数。所谓未充分备份，是指并非所有的 Follower 副本都和 Leader 副本保持同步。一旦出现了这种情况，通常都表明该分区有可能会出现数据丢失。因此，这是一个非常重要的JMX 指标。
* ActiveControllerCount：即当前处于激活状态的控制器的数量。正常情况下，Controller 所在 Broker 上的这个 JMX 指标值应该是 1，其他 Broker 上的这个值是 0。如果你发现存在多台 Broker 上该值都是 1 的情况，一定要赶快处理，处理方式主要是查看网络连通性。这种情况通常表明集群出现了脑裂。脑裂问题是非常严重的分布式故障，Kafka 目前依托 ZooKeeper 来防止脑裂。但一旦出现脑裂，Kafka 是无法保证正常工作的。
* NetworkProcessorAvgIdlePercent：即网络线程池线程平均的空闲比例。通常来说，你应该确保这个 JMX 值长期大于 30%。如果小于这个值，就表明你的网络线程池非常繁忙，你需要通过增加网络线程数或将负载转移给其他服务器的方式，来给该 Broker 减负。
* RequestHandlerAvgIdlePercent：即 I/O 线程池线程平均的空闲比例。同样地，如果该值长期小于 30%，你需要调整 I/O 线程池的数量，或者减少 Broker 端的负载。

## 怎么计算Lag？(注意read_uncommitted和read_committed状态下的不同)
* 如果消费者客户端的`isolation.level`参数配置为`read_uncommitted`（默认）,它对应的 Lag 等于`HW – ConsumerOffset`的值，其中`ConsumerOffset`表示当前的消费位移。
* 如果这个参数配置为`read_committed`，那么就要引入LSO来进行计算了。LSO是`LastStableOffset`的缩写,它对应的 Lag等于`LSO – ConsumerOffset`的值。

## Kafka的那些设计让它有如此高的性能？
### 分区
kafka是个分布式集群的系统，整个系统可以包含多个broker，也就是多个服务器实例。每个主题topic会有多个分区，kafka将分区均匀地分配到整个集群中，当生产者向对应主题传递消息，消息通过负载均衡机制传递到不同的分区以减轻单个服务器实例的压力。一个`Consumer Group`中可以有多个consumer，多个consumer可以同时消费不同分区的消息，大大的提高了消费者的并行消费能力。但是一个分区中的消息在一个`Consumer Group`中只能由一个consumer消费。
### 网络传输上减少开销
#### 批量发送：
在发送消息的时候，kafka不会直接将少量数据发送出去，否则每次发送少量的数据会增加网络传输频率，降低网络传输效率。kafka会先将消息缓存在内存中，当超过一个的大小或者超过一定的时间，那么会将这些消息进行批量发送。
#### 端到端压缩：
当然网络传输时数据量小也可以减小网络负载，kafaka会将这些批量的数据进行压缩，将一批消息打包后进行压缩，再发送到broker服务端。
### 顺序读写
kafka将消息追加到日志文件中，利用了磁盘的顺序读写，来提高读写效率。
### 零拷贝技术
零拷贝将文件内容从磁盘通过DMA引擎复制到内核缓冲区，而且没有把数据复制到socket缓冲区，只是将数据位置和长度信息的描述符复制到了socket缓存区，然后直接将数据传输到网络接口，最后发送。这样大大减小了拷贝的次数，提高了效率。kafka正是调用linux系统给出的sendfile系统调用来使用零拷贝。
### 优秀的文件存储机制
如果分区规则设置得合理，那么所有的消息可以均匀地分布到不同的分区中，这样就可以实现水平扩展。不考虑多副本的情况，一个分区对应一个日志（Log）。为了防止Log过大，Kafka 又引入了日志分段（LogSegment）的概念，将Log切分为多个LogSegment，相当于一个巨型文件被平均分配为多个相对较小的文件，这样也便于消息的维护和清理。Kafka中的索引文件以稀疏索引（sparse index）的方式构造消息的索引，它并不保证每个消息在索引文件中都有对应的索引项。每当写入一定量（由broker端参数`log.index.interval.bytes`指定，默认值为4096，即4KB）的消息时，偏移量索引文件和时间戳索引文件分别增加一个偏移量索引项和时间戳索引项，增大或减小`log.index.interval.bytes`的值，对应地可以增加或缩小索引项的密度。

## 怎么样才能确保Kafka极大程度上的可靠性？
### 副本数量
就Kafka而言，越多的副本数越能够保证数据的可靠性，副本数可以在创建主题时配置，也可以在后期修改，不过副本数越多也会引起磁盘、网络带宽的浪费，同时会引起性能的下降。一般而言，设置副本数为3即可满足绝大多数场景对可靠性的要求，而对可靠性要求更高的场景下，可以适当增大这个数值，比如国内部分银行在使用Kafka时就会设置副本数为5。与此同时，如果能够在分配分区副本的时候引入基架信息(broker.rack参数) ，那么还要应对机架整体岩机的风险。
### acks参数
设置`acks=-1`，写入leader副本且同时同步到ISR中的所有follower副本，才会返回成功。否则，返回异常。结合使用`retries`、`retry.backoff.ms`参数进行失败重试，最好先估算一下可能的异常恢复时间，这样可以设定总的重试时间大于这个异常恢复时间，以此来避免生产者过早地放弃重试。当ISR中只有leader副本时，`acks=-1`演变成为`acks=1`。可以通过`min.insync.replicas`参数作为辅助，当ISR集合副本数量小于该参数时，消息无法写入。
### unclean.leader.election.enable参数
将该参数置为false，默认为false。如果设置为true就意味着当leader下线时候可以从非ISR集合中选举出新的leader，这样有可能造成数据的丢失。
### 同步刷盘策略
在broker端还有两个参数`log.flush.interval.messages`和`log.flush.interval.ms`, 可以用来调整同步刷盘的策略，默认是不做控制而交由操作系统本身来进行处理。同步刷盘是增强一个组件可靠性的有效方式，绝大多数情景下，一个组件(尤其是大数据量的组件)的可靠性不应该由同步刷盘这种极其损耗性能的操作来保障，而应该采用多副本的机制来保障。
### 消费者关闭自动位移
`enable.auto.commit`参数的默认值为true，即开启自动位移提交的功能，虽然这种方式非常简便，但它会带来重复消费和消息丢失的问题，对于高可靠性要求的应用来说显然不可 取，所以需要将`enable.auto.commit`参数设置为`false`来执行手动位移提交。在执行手动位移提交的时候也要遵循一个原则: 如果消息没有被成功消费，那么就不能提交所对应的消费位移。对于高可靠要求的应用来说，宁愿重复消费也不应该因为消费异常而导致消息丢失。有时候，由于应用解析消息的异常，可能导致部分消息一直不能够成功被消费，那么这个时候为了不影响整体消费的进度，可以将这类消息暂存到死信队列，以便后续的故障排除。同时，必要时通过指定消费者位移进行回溯消费兜底。

## Kafka中的事务是怎么实现的（这题我去面试6家被问4次，照着答案念也要念十几分钟，面试官简直凑不要脸。实在记不住的话...只要简历上不写精通Kafka一般不会问到，我简历上写的是“熟悉Kafka，了解RabbitMQ....”）

## Kafka有什么优缺点？

## 还用过什么同质类的其它产品，与Kafka相比有什么优缺点？

## 为什么选择Kafka?

## 在使用Kafka的过程中遇到过什么困难？怎么解决的？

## Kafka中有那些配置参数比较有意思？聊一聊你的看法

## Kafka中有那些命名比较有意思？聊一聊你的看法

## 聊一聊你对Kafka生态的理解

## 参考链接
* <https://mp.weixin.qq.com/s/I-YsRKcjcBv4eOop-jjO0A>
* <https://juejin.im/post/5b41fe36e51d45191252e79e>
* <https://www.dazhuanlan.com/2019/10/27/5db52fbab04aa/>
* <https://www.cnblogs.com/luozhiyun/p/12079527.html>
* <http://matt33.com/2018/11/04/kafka-transaction/>