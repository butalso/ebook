# 缓存

## 什么是缓存
缓存一词最开始用于CPU和主内存之间，原始意义是指访问速度比一般随机存取存储器(RAM)快的一种RAM。现如今，凡是位于速度相差较大的两种硬件之间，用于协调两者数据传输差异的结构，均可称为缓存。比如在内存和硬盘之间的磁盘缓存，硬盘与网络之间Internet临时文件夹或网络内容缓存。在互联网行业，常常需要通过缓存数据库中的数据来实现应用的高性能和高并发。

## 缓存特征
* 命中率：`命中率=返回正确结果数/请求缓存次数`
* 最大空间：可支持缓存数据所占空间的最大值，一旦元素数量超过这个值，将会触发缓存淘汰策略。
* 淘汰策略：如FIFO、LRU、LFU等。

## 缓存分类（按缓存与应用的耦合度)
* 本地缓存(local cache)：指的是在应用中的缓存组件，其最大的优点是应用和cache是在同一个进程内部，请求缓存非常快速，没有过多的网络开销等，在单应用不需要集群支持或者集群情况下各节点无需互相通知的场景下使用本地缓存较合适；同时，它的缺点也是应为缓存跟应用程序耦合，多个应用程序无法直接的共享缓存，各应用或集群的各节点都需要维护自己的单独缓存，对内存是一种浪费,而且，不同节点间可能存在数据不一致问题，使用时需要考虑缓存数据的时效性。
* 分布式缓存(remote cache):指的是与应用分离的缓存组件或服务，其最大的优点是自身就是一个独立的应用，与本地应用隔离，多个应用可直接的共享缓存。缺点就是请求会有网络开销。

### 本地缓存
### 分布式缓存
#### memcached
memcached本身其实不提供分布式解决方案。在服务端，memcached集群环境实际就是一个个memcached服务器的堆积，环境搭建较为简单；cache的分布式主要是在客户端实现，通过客户端的路由处理来达到分布式解决方案的目的。客户端做路由的原理非常简单，应用服务器在每次存取某key的value时，通过某种算法把key映射到某台memcached服务器nodeA上，因此这个key所有操作都在nodeA上，

memcached仅支持基础的key-value键值对类型数据存储。在memcached内存结构中有两个非常重要的概念：slab和chunk。

slab是一个内存块，它是memcached一次申请内存的最小单位。在启动memcached的时候一般会使用参数-m指定其可用内存，但是并不是在启动的那一刻所有的内存就全部分配出去了，只有在需要的时候才会去申请，而且每次申请一定是一个slab。Slab的大小固定为1M（1048576 Byte），一个slab由若干个大小相等的chunk组成。每个chunk中都保存了一个item结构体、一对key和value。

虽然在同一个slab中chunk的大小相等的，但是在不同的slab中chunk的大小并不一定相等，在memcached中按照chunk的大小不同，可以把slab分为很多种类（class），默认情况下memcached把slab分为40类（class1～class40），在class 1中，chunk的大小为80字节，由于一个slab的大小是固定的1048576字节（1M），因此在class1中最多可以有13107个chunk（也就是这个slab能存最多13107个小于80字节的key-value数据）。

memcached内存管理采取预分配、分组管理的方式，分组管理就是我们上面提到的slab class，按照chunk的大小slab被分为很多种类。内存预分配过程是怎样的呢？向memcached添加一个item时候，memcached首先会根据item的大小，来选择最合适的slab class：例如item的大小为190字节，默认情况下class 4的chunk大小为160字节显然不合适，class 5的chunk大小为200字节，大于190字节，因此该item将放在class 5中（显然这里会有10字节的浪费是不可避免的），计算好所要放入的chunk之后，memcached会去检查该类大小的chunk还有没有空闲的，如果没有，将会申请1M（1个slab）的空间并划分为该种类chunk。例如我们第一次向memcached中放入一个190字节的item时，memcached会产生一个slab class 2（也叫一个page），并会用去一个chunk，剩余5241个chunk供下次有适合大小item时使用，当我们用完这所有的5242个chunk之后，下次再有一个在160～200字节之间的item添加进来时，memcached会再次产生一个class 5的slab（这样就存在了2个pages）。

总结来看，memcached内存管理需要注意的几个方面：

* chunk是在page里面划分的，而page固定为1m，所以chunk最大不能超过1m。
* chunk实际占用内存要加48B，因为chunk数据结构本身需要占用48B。
* 如果用户数据大于1m，则memcached会将其切割，放到多个chunk内。
* 已分配出去的page不能回收。
#### Redis

## 缓存更新
### Cache Aside Pattern(最常用)
即先更新数据库，再删除缓存
* 失效： 应用程序先从cache取数据，没有得到，则从数据库中取数据，成功后，放到缓存中
* 命中： 应用程序从cache中取数据，取到后返回
* 更新： 应用程序把数据存到数据库中，成功后，让缓存失效

#### 为什么不先更新数据库，再更新缓存
这种做法最大的问题就是**两个并发写操作可能会导致脏数据**。假设有两个并发更新操作，数据库先更新的反而后更新缓存，数据库后更新的反而先更新缓存，这样就会造成数据库和缓存中的数据不一致。

再者，每次修改都更新缓存，假如这个缓存数据更新频繁且读的较少，则相当于浪费了更新缓存的计算资源。
#### 为什么不先删除缓存，再更新数据库
这种做法的问题就是**两个请求，一个读一个写可能会导致脏数据**。假设有两个并发操作，一个更新操作，一个查询操作，更新操作删除缓存后，查询操作没有命中缓存，先把老数据都出来后放到缓存中，然后更新操作更新了数据库。于是，在缓存中的数据还是老数据，导致缓存中的数据时脏的直到失效。
#### 先更新数据库，再删除缓存有没有可能导致问题
这种做法是最常用也是最推荐的，理论上也会存在问题。假设有两个请求，一个查询请求，一个更新请求。查询操作没有命中缓存，然后从数据库中查出老数据。此时一个并发的更新操作，更新操作在读操作之后更新了数据库中的数据并且删除缓存。然后查询操作再把老数据放到缓存中，导致缓存中有脏数据。

但是，这个case理论上会出现，实际上出现的概率可能非常低，因为这个条件需要发生在读缓存时缓存失效，而且并发着一个写操作，读操作必须在写操作前读取数据，并且要晚于写操作更新缓存。而实际上数据库的写操作会比读操作慢得多，需要锁表，所有这些条件都具备的可能性不大。

### Read/Write Through Pattern
在Cache Aside模式中，我们的应用代码需要维护两个数据，一个是缓存，一个是数据库。所以，应用程序比较啰嗦。而Read/Write Throgh模式把更新数据库的操作由缓存代理，对于应用层来说，可以认为只有一个单一的存储，存储自己维护自己的cache。
#### Read Through
查询操作中更新缓存，也就是说，当缓存失效的时候（过期或者内存淘汰），Cache Aside是由调用方负责把数据加载到缓存，而Read Through则由缓存服务自己来加载，对调用方来说缓存是透明的。
#### Write Through
当有数据需要更新的时候，如果没有命中缓存，直接更新数据库，然后返回。如果命中了缓存，则更新缓存，然后再由缓存自己更新数据库。

### Write Behind Cache Pattern
在更新数据的时候，只更新缓存，不更新数据库，而我们的缓存会异步地批量更新数据库。
### 总结
* Cache Aside 更新模式实现起来比较简单，但是需要维护两个数据存储，一个是缓存（Cache），一个是数据库（Repository）。
* Read/Write Through 更新模式只需要维护一个数据存储（缓存），但是实现起来要复杂一些。
* Write Behind Caching 更新模式和Read/Write Through 更新模式类似，区别是Write Behind Caching 更新模式的数据持久化操作是异步的，但是Read/Write Through 更新模式的数据持久化操作是同步的。优点是直接操作内存速度快，多次操作可以合并持久化到数据库。缺点是数据可能会丢失，例如系统断电等。

## 使用缓存可能带来的问题
* 数据不一致
* 缓存雪崩
* 缓存穿透
* 缓存击穿

### 缓存穿透
#### 定义
缓存穿透是指查询一个一定不存在的数据，由于缓存是不命中时被动写的，并且出于容错考虑，如果从存储层查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到存储层去查询，降低缓存命中率，同时，可能有黑客使用不存在的key大量请求，打挂db
#### 解决方案
* 缓存空值：将不存在的key值也设到缓存中去，避免打到db，同时设置一个短暂的超时时间
* 布隆过滤器：将所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被这个bitmap拦截掉，从而避免了对底层存储系统的查询压力

### 缓存雪崩
#### 定义
当某一时刻发生大规模的缓存失效，比如缓存服务宕机、大量缓存key值同时失效
#### 解决方案
* 采用集群，降低服务宕机的概率
* Hystrix限流&降级
* 为数据设置不同的失效时间，可以在一个基础值上加一个随机数
* 多级缓存

### 缓存击穿
#### 定义
**热点数据**失效时，大量请求打到db。缓存击穿和缓存雪崩的区别在于缓存击穿针对某一key缓存，缓存雪崩则是很多key。
#### 解决方案
* 读db抢分布式互斥锁（业界常用）
* 数据不过期，可采用定时任务将对快要失效的缓存进行更新

## 参考连接
* <https://tech.meituan.com/2017/03/17/cache-about.html>
* <https://coolshell.cn/articles/17416.html>
* <https://juejin.im/post/5af5b2c36fb9a07ac65318bd>
* <https://juejin.im/post/5ca8905ef265da30ba5b18bc>
* <https://blog.csdn.net/zeb_perfect/article/details/54135506>